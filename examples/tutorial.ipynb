{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YOLO11 Tutorial",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/simbakm/training_yolov11_notebook/blob/main/examples/tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6MPjfT5NrKQ"
      },
      "source": [
        "# **starting Point @ simbakm Training YOlo  version 11 bold text**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mGmQbAO5pQb"
      },
      "source": [
        "# Setup\n",
        "\n",
        "pip install `ultralytics` and [dependencies](https://github.com/ultralytics/ultralytics/blob/main/pyproject.toml) and check software and hardware.\n",
        "\n",
        "[![PyPI - Version](https://img.shields.io/pypi/v/ultralytics?logo=pypi&logoColor=white)](https://pypi.org/project/ultralytics/) [![Downloads](https://static.pepy.tech/badge/ultralytics)](https://clickpy.clickhouse.com/dashboard/ultralytics) [![PyPI - Python Version](https://img.shields.io/pypi/pyversions/ultralytics?logo=python&logoColor=gold)](https://pypi.org/project/ultralytics/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbvMlHd_QwMG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58072e7a-833e-4770-e8b2-593f5e3d7f12"
      },
      "source": [
        "!uv pip install ultralytics\n",
        "!pip install roboflow kagglehub\n",
        "import ultralytics\n",
        "import os\n",
        "import shutil\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "import random\n",
        "from ultralytics import YOLO\n",
        "ultralytics.checks()\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.4.14 üöÄ Python-3.12.12 torch-2.9.0+cu128 CUDA:0 (Tesla T4, 14913MiB)\n",
            "Setup complete ‚úÖ (2 CPUs, 12.7 GB RAM, 41.9/112.6 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**check for GPU**"
      ],
      "metadata": {
        "id": "2BwEhVXdwnri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "print(f\"Using {device} device.\")"
      ],
      "metadata": {
        "id": "1JBHKWKxwnXQ",
        "outputId": "1605c724-0d2d-4b77-d93a-a5760c5177ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**STEP 2 ‚Äî Download the Roboflow dataset (YOLOv11-ready)bold text**"
      ],
      "metadata": {
        "id": "8I6sumtzqek_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**helper fuction to couint the number of files**"
      ],
      "metadata": {
        "id": "5oUlOF0jjOUJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from collections import defaultdict\n",
        "\n",
        "def count_file_types(dataset_path):\n",
        "    file_counts = defaultdict(int)\n",
        "\n",
        "    for root, dirs, files in os.walk(dataset_path):\n",
        "        for file in files:\n",
        "            ext = os.path.splitext(file)[1].lower()  # get file extension\n",
        "            file_counts[ext] += 1\n",
        "\n",
        "    print(\"File type counts:\\n\")\n",
        "    for ext, count in sorted(file_counts.items()):\n",
        "        print(f\"{ext if ext else 'No Extension'} : {count}\")\n",
        "\n",
        "    return dict(file_counts)\n"
      ],
      "metadata": {
        "id": "E-Ssey6njIMB"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"YdrZFjwWblcZBkXrqqaR\")\n",
        "project = rf.workspace(\"stairs-ttqqp\").project(\"trash-bin-asn0s\")\n",
        "dataset = project.version(1).download(\"yolov11\")\n",
        "\n",
        "roboflow_path = dataset.location\n",
        "print(\"Roboflow dataset:\", roboflow_path)\n",
        "\n",
        "counts = count_file_types(roboflow_path)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwsMXa8YnYMe",
        "outputId": "9636c692-e4a4-4f9f-c43b-410906bd3f43"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Roboflow dataset: /content/trash-bin-1\n",
            "File type counts:\n",
            "\n",
            ".jpg : 445\n",
            ".txt : 447\n",
            ".yaml : 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **STEP 3: Download the TACO dataset from KaggleHub**"
      ],
      "metadata": {
        "id": "xGzsfpkwp2mS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "path = kagglehub.dataset_download(\"kneroma/tacotrashdataset\")\n",
        "print(\"Downloaded to:\", path)\n",
        "counts = count_file_types(path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XS_K-gNBpbZ8",
        "outputId": "4e5e42e0-ac52-45e6-d11c-1255f2b7e4f8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'tacotrashdataset' dataset.\n",
            "Downloaded to: /kaggle/input/tacotrashdataset\n",
            "File type counts:\n",
            "\n",
            ".bin : 1\n",
            ".csv : 1\n",
            ".jpg : 1500\n",
            ".json : 1\n",
            ".txt : 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**STEP 4 ‚Äî Convert TACO (COCO JSON) ‚Üí YOLO format**"
      ],
      "metadata": {
        "id": "MAU8pdKBq3E6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# TACO dataset path (from KaggleHub)\n",
        "taco_path = path\n",
        "data_dir = os.path.join(taco_path, \"data\")\n",
        "\n",
        "# Load annotations\n",
        "annotations_path = os.path.join(data_dir, \"annotations.json\")\n",
        "annotations = json.load(open(annotations_path))\n",
        "\n",
        "# Output\n",
        "output_taco = \"/content/taco_yolo\"\n",
        "#delete privous derectories\n",
        "if os.path.exists(output_taco):\n",
        "    shutil.rmtree(output_taco)\n",
        "    print(\"Old taco_yolo directory removed.\")\n",
        "else:\n",
        "    print(\"No previous taco_yolo folder found.\")\n",
        "\n",
        "os.makedirs(f\"{output_taco}/images\", exist_ok=True)\n",
        "os.makedirs(f\"{output_taco}/labels\", exist_ok=True)\n",
        "\n",
        "# Map image id ‚Üí image info\n",
        "image_map = {img[\"id\"]: img for img in annotations[\"images\"]}\n",
        "\n",
        "# Find all images recursively\n",
        "all_images = {}\n",
        "image_files = glob(f\"{data_dir}/**/*.jpg\", recursive=True) + \\\n",
        "              glob(f\"{data_dir}/**/*.JPG\", recursive=True)\n",
        "\n",
        "for f in image_files:\n",
        "    all_images[os.path.relpath(f, data_dir)] = f\n",
        "\n",
        "\n",
        "print(\"Total images found:\", len(all_images))\n",
        "\n",
        "# Group annotations by image ID\n",
        "ann_by_image = {}\n",
        "for ann in annotations[\"annotations\"]:\n",
        "    img_id = ann[\"image_id\"]\n",
        "    ann_by_image.setdefault(img_id, []).append(ann)\n",
        "\n",
        "# Convert to YOLO\n",
        "for img_id, img_info in tqdm(image_map.items()):\n",
        "    filename = img_info[\"file_name\"]\n",
        "    batch_relative_path = filename  # contains batch_x/000000.jpg\n",
        "\n",
        "    if batch_relative_path not in all_images:\n",
        "        print(\"Missing image:\", batch_relative_path)\n",
        "        continue\n",
        "\n",
        "    src = all_images[batch_relative_path]\n",
        "\n",
        "    # create unique new filename based on img_id\n",
        "    new_name = f\"{img_id}.jpg\"\n",
        "    dst = f\"{output_taco}/images/{new_name}\"\n",
        "\n",
        "    shutil.copy(src, dst)\n",
        "\n",
        "    # image width/height\n",
        "    W = img_info[\"width\"]\n",
        "    H = img_info[\"height\"]\n",
        "\n",
        "    # label path (same name as image)\n",
        "    label_path = f\"{output_taco}/labels/{img_id}.txt\"\n",
        "    with open(label_path, \"w\") as f:\n",
        "        for ann in ann_by_image.get(img_id, []):\n",
        "            x, y, w, h = ann[\"bbox\"]\n",
        "\n",
        "            # convert to YOLO\n",
        "            xc = (x + w/2) / W\n",
        "            yc = (y + h/2) / H\n",
        "            w /= W\n",
        "            h /= H\n",
        "            # Create category id mapping\n",
        "            categories = annotations[\"categories\"]\n",
        "            cat_id_map = {cat[\"id\"]: i for i, cat in enumerate(categories)}\n",
        "            class_id = cat_id_map[ann[\"category_id\"]]\n",
        "\n",
        "            f.write(f\"{class_id} {xc} {yc} {w} {h}\\n\")\n",
        "\n",
        "print(\"DONE ‚Äî TACO converted to YOLO:\", output_taco)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujxSaGGlq8LN",
        "outputId": "d4a5f105-4fb1-48c8-81bf-75685536a305"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No previous taco_yolo folder found.\n",
            "Total images found: 1500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1500/1500 [00:42<00:00, 35.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DONE ‚Äî TACO converted to YOLO: /content/taco_yolo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5: Split the dataset into Train,val and test using ratio 80|10|10**"
      ],
      "metadata": {
        "id": "2Vg63xcK29RE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, random, shutil\n",
        "from glob import glob\n",
        "\n",
        "taco_img = \"/content/taco_yolo/images\"\n",
        "taco_lbl = \"/content/taco_yolo/labels\"\n",
        "\n",
        "images = sorted(glob(f\"{taco_img}/*.jpg\"))\n",
        "random.shuffle(images)\n",
        "\n",
        "n = len(images)\n",
        "train_split = int(n * 0.8)\n",
        "val_split = int(n * 0.9)\n",
        "\n",
        "train_files = images[:train_split]\n",
        "val_files   = images[train_split:val_split]\n",
        "test_files  = images[val_split:]\n",
        "\n",
        "def copy_split(files, folder):\n",
        "    os.makedirs(f\"/content/taco_split/images/{folder}\", exist_ok=True)\n",
        "    os.makedirs(f\"/content/taco_split/labels/{folder}\", exist_ok=True)\n",
        "    for img in files:\n",
        "        lbl = img.replace(\"images\", \"labels\").replace(\".jpg\", \".txt\")\n",
        "        shutil.copy(img, f\"/content/taco_split/images/{folder}/\")\n",
        "        shutil.copy(lbl, f\"/content/taco_split/labels/{folder}/\")\n",
        "\n",
        "copy_split(train_files, \"train\")\n",
        "copy_split(val_files, \"val\")\n",
        "copy_split(test_files, \"test\")\n",
        "\n",
        "print(\"TACO split complete!\")\n"
      ],
      "metadata": {
        "id": "6y816cQX26gg",
        "outputId": "0243c215-ba5d-4f52-a2e3-d3a375801839",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TACO split complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Group TACO Classes into 10 & Shift IDs (COCO=0‚Äì79, TACO=80‚Äì89)**"
      ],
      "metadata": {
        "id": "NMCUdIdQUPQ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "taco_group_map = {\n",
        "    0:0,1:0,2:0,3:0,      # Plastic -> class 0\n",
        "    4:1,5:1,              # Glass -> class 1\n",
        "    6:2,7:2,8:2,          # Metal -> class 2\n",
        "    9:3,10:3,             # Paper/Cardboard -> class 3\n",
        "    11:4,                  # Cigarette -> class 4\n",
        "    12:5,13:5,14:5,       # Food wrapper -> class 5\n",
        "    15:6,                  # Styrofoam -> class 6\n",
        "    16:7,17:7,            # Rubber/Textile -> class 7\n",
        "    18:8,19:8,            # Organic -> class 8\n",
        "    20:9,21:9,22:9        # Electronics/Other -> class 9\n",
        "}\n",
        "\n",
        "# NO OFFSET - TACO classes will be 0-9\n",
        "for split in [\"train\", \"val\", \"test\"]:\n",
        "    lbl_files = glob.glob(f\"/content/taco_split/labels/{split}/*.txt\")\n",
        "    for file in lbl_files:\n",
        "        new_lines = []\n",
        "        with open(file, \"r\") as f:\n",
        "            for line in f:\n",
        "                parts = line.strip().split()\n",
        "                if len(parts) > 0:\n",
        "                    original_id = int(parts[0])\n",
        "                    if original_id in taco_group_map:\n",
        "                        grouped_id = taco_group_map[original_id]  # This gives 0-9\n",
        "                        parts[0] = str(grouped_id)  # Direct mapping, no offset\n",
        "                        new_lines.append(\" \".join(parts))\n",
        "        with open(file, \"w\") as f:\n",
        "            f.write(\"\\n\".join(new_lines))\n",
        "\n",
        "print(\"TACO grouped into 10 classes (classes 0-9):\")\n",
        "class_names = [\"plastic\", \"glass\", \"metal\", \"paper\", \"cigarette\",\n",
        "               \"food_wrapper\", \"styrofoam\", \"rubber_textile\", \"organic\", \"electronics_other\"]\n",
        "for i, name in enumerate(class_names):\n",
        "    print(f\"  Class {i}: {name}\")"
      ],
      "metadata": {
        "id": "YfJtJGTHUO7V",
        "outputId": "1689496c-69a7-4e2e-8891-5c5da6a0e542",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TACO grouped into 10 classes (classes 0-9):\n",
            "  Class 0: plastic\n",
            "  Class 1: glass\n",
            "  Class 2: metal\n",
            "  Class 3: paper\n",
            "  Class 4: cigarette\n",
            "  Class 5: food_wrapper\n",
            "  Class 6: styrofoam\n",
            "  Class 7: rubber_textile\n",
            "  Class 8: organic\n",
            "  Class 9: electronics_other\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**STEP 6 ‚Äî move trans bin to class 90**"
      ],
      "metadata": {
        "id": "kWvTXXoIEOOW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "\n",
        "rf_labels = glob.glob(f\"{roboflow_path}/**/labels/*.txt\", recursive=True)\n",
        "\n",
        "for file in rf_labels:\n",
        "    lines = []\n",
        "    with open(file, \"r\") as f:\n",
        "        for line in f:\n",
        "            parts = line.strip().split()\n",
        "            if len(parts) > 0:\n",
        "                parts[0] = \"10\"  # Move to class 10 (trash bin)\n",
        "                lines.append(\" \".join(parts))\n",
        "\n",
        "    if lines:  # Only write if there are lines\n",
        "        with open(file, \"w\") as f:\n",
        "            f.write(\"\\n\".join(lines))\n",
        "\n",
        "print(f\"Roboflow labels shifted to class 10 (trash bin). Processed {len(rf_labels)} files.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9KdLht_q48H",
        "outputId": "22516a4b-d559-42de-e75e-299841fc5c07"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Roboflow labels shifted to class 10 (trash bin). Processed 445 files.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create a combined Dataset**"
      ],
      "metadata": {
        "id": "YsH4oUfVyhnZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import random\n",
        "\n",
        "# Remove old combined folder\n",
        "shutil.rmtree(\"/content/combined\", ignore_errors=True)\n",
        "\n",
        "# Create combined structure\n",
        "for split in [\"train\", \"val\", \"test\"]:\n",
        "    os.makedirs(f\"/content/combined/images/{split}\", exist_ok=True)\n",
        "    os.makedirs(f\"/content/combined/labels/{split}\", exist_ok=True)\n",
        "\n",
        "# Copy TACO dataset (classes 0-9)\n",
        "print(\"Copying TACO dataset (classes 0-9)...\")\n",
        "taco_dirs = {\n",
        "    'train': '/content/taco_split/images/train',\n",
        "    'val': '/content/taco_split/images/val',\n",
        "    'test': '/content/taco_split/images/test'\n",
        "}\n",
        "\n",
        "taco_counts = {}\n",
        "for split, path in taco_dirs.items():\n",
        "    if os.path.exists(path):\n",
        "        # Copy images\n",
        "        !cp -r {path}/* /content/combined/images/{split}/ 2>/dev/null\n",
        "\n",
        "        # Copy labels\n",
        "        label_path = path.replace('images', 'labels')\n",
        "        if os.path.exists(label_path):\n",
        "            !cp -r {label_path}/* /content/combined/labels/{split}/ 2>/dev/null\n",
        "\n",
        "        # Count copied items\n",
        "        img_count = len(glob.glob(f\"/content/combined/images/{split}/*.jpg\"))\n",
        "        taco_counts[split] = img_count\n",
        "        print(f\"  Copied {img_count} TACO images to {split} (classes 0-9)\")\n",
        "\n",
        "# Copy Roboflow dataset (class 10 - trash bin)\n",
        "print(\"\\nCopying Roboflow dataset (class 10 - trash bin)...\")\n",
        "\n",
        "\n",
        "if os.path.exists(roboflow_path):\n",
        "    roboflow_counts = {}\n",
        "    for split in ['train', 'valid', 'test']:\n",
        "        target_split = 'val' if split == 'valid' else split\n",
        "\n",
        "        # Copy images\n",
        "        img_source = f\"{roboflow_path}/{split}/images\"\n",
        "        if os.path.exists(img_source):\n",
        "            !cp -r {img_source}/* /content/combined/images/{target_split}/ 2>/dev/null\n",
        "\n",
        "        # Copy labels\n",
        "        label_source = f\"{roboflow_path}/{split}/labels\"\n",
        "        if os.path.exists(label_source):\n",
        "            !cp -r {label_source}/* /content/combined/labels/{target_split}/ 2>/dev/null\n",
        "\n",
        "        # Count copied items\n",
        "        img_count = len(glob.glob(f\"/content/combined/images/{target_split}/*.jpg\"))\n",
        "        roboflow_counts[target_split] = img_count\n",
        "        print(f\"  Copied {img_count} Roboflow images to {target_split} (class 10)\")\n",
        "else:\n",
        "    print(f\"  Warning: Roboflow path {roboflow_path} does not exist!\")\n",
        "    print(\"  Please update the roboflow_path variable with the correct path.\")\n",
        "\n",
        "# Final verification\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"FINAL COMBINED DATASET COUNTS (11 total classes: 0-10)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "total_images = 0\n",
        "total_labels = 0\n",
        "\n",
        "for split in [\"train\", \"val\", \"test\"]:\n",
        "    images = glob.glob(f\"/content/combined/images/{split}/*.jpg\")\n",
        "    labels = glob.glob(f\"/content/combined/labels/{split}/*.txt\")\n",
        "    print(f\"{split.upper():5} - Images: {len(images):6d}, Labels: {len(labels):6d}\")\n",
        "    total_images += len(images)\n",
        "    total_labels += len(labels)\n",
        "\n",
        "    # Check for missing labels\n",
        "    missing = 0\n",
        "    for img in images:\n",
        "        label = img.replace('/images/', '/labels/').replace('.jpg', '.txt')\n",
        "        if not os.path.exists(label):\n",
        "            missing += 1\n",
        "    if missing > 0:\n",
        "        print(f\"         ‚ö†Ô∏è  Warning: {missing} images missing labels in {split}\")\n",
        "    else:\n",
        "        print(f\"         ‚úÖ All images have corresponding labels in {split}\")\n",
        "\n",
        "    # Check class distribution in this split\n",
        "    class_counts = {i:0 for i in range(11)}  # Initialize all 11 classes\n",
        "    for label_file in labels:\n",
        "        with open(label_file, 'r') as f:\n",
        "            for line in f:\n",
        "                if line.strip():\n",
        "                    class_id = int(line.strip().split()[0])\n",
        "                    if class_id in class_counts:\n",
        "                        class_counts[class_id] += 1\n",
        "\n",
        "    print(f\"         Class distribution in {split}:\")\n",
        "    class_names = [\"plastic\", \"glass\", \"metal\", \"paper\", \"cigarette\",\n",
        "                   \"food_wrapper\", \"styrofoam\", \"rubber_textile\", \"organic\",\n",
        "                   \"electronics_other\", \"trash_bin\"]\n",
        "    for i in range(11):\n",
        "        if class_counts[i] > 0:\n",
        "            print(f\"           Class {i} ({class_names[i]}): {class_counts[i]}\")\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(f\"TOTAL - Images: {total_images}, Labels: {total_labels}\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "34PrwXcA2E8f",
        "outputId": "f35d3fc8-5828-4872-c0cd-21404f7c5310",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying TACO dataset (classes 0-9)...\n",
            "  Copied 1200 TACO images to train (classes 0-9)\n",
            "  Copied 150 TACO images to val (classes 0-9)\n",
            "  Copied 150 TACO images to test (classes 0-9)\n",
            "\n",
            "Copying Roboflow dataset (class 10 - trash bin)...\n",
            "  Copied 1514 Roboflow images to train (class 10)\n",
            "  Copied 255 Roboflow images to val (class 10)\n",
            "  Copied 176 Roboflow images to test (class 10)\n",
            "\n",
            "============================================================\n",
            "FINAL COMBINED DATASET COUNTS (11 total classes: 0-10)\n",
            "============================================================\n",
            "TRAIN - Images:   1514, Labels:   1514\n",
            "         ‚úÖ All images have corresponding labels in train\n",
            "         Class distribution in train:\n",
            "           Class 10 (trash_bin): 398\n",
            "VAL   - Images:    255, Labels:    255\n",
            "         ‚úÖ All images have corresponding labels in val\n",
            "         Class distribution in val:\n",
            "           Class 10 (trash_bin): 139\n",
            "TEST  - Images:    176, Labels:    176\n",
            "         ‚úÖ All images have corresponding labels in test\n",
            "         Class distribution in test:\n",
            "           Class 10 (trash_bin): 32\n",
            "============================================================\n",
            "TOTAL - Images: 1945, Labels: 1945\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "count the images in each category -> train,val and test"
      ],
      "metadata": {
        "id": "qjBm2R-ezndu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**step7: Create YOLO data.yaml**"
      ],
      "metadata": {
        "id": "HmgOeBR75SDJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Define our 11 classes (TACO 0-9 + Trash Bin 10)\n",
        "final_names = [\n",
        "    # TACO grouped classes (10 classes) - classes 0-9\n",
        "    \"plastic\",           # class 0\n",
        "    \"glass\",             # class 1\n",
        "    \"metal\",             # class 2\n",
        "    \"paper\",             # class 3\n",
        "    \"cigarette\",         # class 4\n",
        "    \"food_wrapper\",      # class 5\n",
        "    \"styrofoam\",         # class 6\n",
        "    \"rubber_textile\",    # class 7\n",
        "    \"organic\",           # class 8\n",
        "    \"electronics_other\", # class 9\n",
        "\n",
        "    # Roboflow class (1 class) - class 10\n",
        "    \"trash_bin\"          # class 10\n",
        "]\n",
        "\n",
        "# Create combined.yaml\n",
        "with open(\"combined.yaml\", \"w\") as f:\n",
        "    f.write(\"# TACO (10 classes: 0-9) + Trash Bin (1 class: 10) dataset\\n\\n\")\n",
        "    f.write(\"train: /content/combined/images/train\\n\")\n",
        "    f.write(\"val: /content/combined/images/val\\n\")\n",
        "    f.write(\"test: /content/combined/images/test\\n\\n\")\n",
        "    f.write(f\"nc: {len(final_names)}  # 11 classes total (0-10)\\n\")\n",
        "    f.write(\"names:\\n\")\n",
        "    for name in final_names:\n",
        "        f.write(f\"  - {name}\\n\")\n",
        "\n",
        "print(\"‚úÖ combined.yaml created with 11 classes (0-10):\")\n",
        "for i, name in enumerate(final_names):\n",
        "    print(f\"   Class {i}: {name}\")\n",
        "\n",
        "# Verify the paths exist\n",
        "print(\"\\nVerifying paths:\")\n",
        "for split in [\"train\", \"val\", \"test\"]:\n",
        "    path = f\"/content/combined/images/{split}\"\n",
        "    if os.path.exists(path):\n",
        "        count = len(glob.glob(f\"{path}/*.jpg\"))\n",
        "        print(f\"  {split}: {path} - {count} images ‚úÖ\")\n",
        "    else:\n",
        "        print(f\"  {split}: {path} - NOT FOUND ‚ùå\")"
      ],
      "metadata": {
        "id": "03jXia1KqUSe",
        "outputId": "1916d34d-9ff8-4a25-e037-4b9142334fdf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ combined.yaml created with 11 classes (0-10):\n",
            "   Class 0: plastic\n",
            "   Class 1: glass\n",
            "   Class 2: metal\n",
            "   Class 3: paper\n",
            "   Class 4: cigarette\n",
            "   Class 5: food_wrapper\n",
            "   Class 6: styrofoam\n",
            "   Class 7: rubber_textile\n",
            "   Class 8: organic\n",
            "   Class 9: electronics_other\n",
            "   Class 10: trash_bin\n",
            "\n",
            "Verifying paths:\n",
            "  train: /content/combined/images/train - 1514 images ‚úÖ\n",
            "  val: /content/combined/images/val - 255 images ‚úÖ\n",
            "  test: /content/combined/images/test - 176 images ‚úÖ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **8: ‚Äî Train YOLOv11**"
      ],
      "metadata": {
        "id": "kCuUDEdq5j1B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Path to your combined YAML\n",
        "data_yaml = \"combined.yaml\"\n",
        "\n",
        "# Use YOLO11n pretrained on COCO as base\n",
        "model = YOLO(\"yolo11n.pt\")\n",
        "\n",
        "# Training parameters - saving to default path /content/runs/detect/train/\n",
        "model.train(\n",
        "    data=data_yaml,        # 11-class dataset (0-10)\n",
        "    epochs=100,            # max epochs\n",
        "    imgsz=640,             # image size\n",
        "    batch=16,              # adjust to GPU memory\n",
        "    device=device,         # device is already defined in previous cells\n",
        "    patience=10,           # early stopping if val mAP not improving for 10 epochs\n",
        "    save=True,             # saves best.pt automatically\n",
        "    pretrained=True,       # start from COCO weights\n",
        "    optimizer='auto',      # YOLO chooses best optimizer\n",
        "    lr0=0.01,              # initial learning rate\n",
        "    augment=True,          # enables basic augmentations\n",
        "\n",
        "    # Augmentation parameters\n",
        "    mosaic=1.0,            # mosaic augmentation (0-1 probability)\n",
        "    mixup=0.1,             # mixup augmentation (0-1 probability)\n",
        "    flipud=0.0,            # vertical flip - 0.0 as trash isn't usually upside down\n",
        "    fliplr=0.5,            # horizontal flip - useful for symmetry\n",
        "    hsv_h=0.015,           # hue jitter\n",
        "    hsv_s=0.7,             # saturation jitter\n",
        "    hsv_v=0.4,             # value (brightness) jitter\n",
        "    degrees=0.0,           # rotation (0 for no rotation - keeps annotations valid)\n",
        "    translate=0.1,         # translation\n",
        "    scale=0.5,             # scaling\n",
        "    shear=0.0,             # shear (keep 0 to avoid distortion)\n",
        "\n",
        "    # Training settings\n",
        "    deterministic=True,    # reproducible results\n",
        "    save_period=5,         # save weights every 5 epochs\n",
        "    plots=True,            # generate loss/metrics plots automatically\n",
        "    workers=8,             # number of dataloader workers\n",
        "    seed=42,               # for reproducibility\n",
        "    verbose=True           # print detailed output\n",
        "    # project and name are removed - will use default: runs/detect/train/\n",
        ")\n"
      ],
      "metadata": {
        "id": "tij-K73T5tNg",
        "outputId": "5b2fd247-1abb-4197-d4d9-033bd6d78eae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, angle=1.0, augment=True, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=combined.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, end2end=None, epochs=100, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.1, mode=train, model=yolo11n.pt, momentum=0.937, mosaic=1.0, multi_scale=0.0, name=train4, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, rle=1.0, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/detect/train4, save_frames=False, save_json=False, save_period=5, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=11\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
            "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
            " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
            " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
            " 23        [16, 19, 22]  1    432817  ultralytics.nn.modules.head.Detect           [11, 16, None, [64, 128, 256]]\n",
            "YOLO11n summary: 182 layers, 2,591,985 parameters, 2,591,969 gradients, 6.5 GFLOPs\n",
            "\n",
            "Transferred 448/499 items from pretrained weights\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1639.0¬±917.0 MB/s, size: 385.7 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/combined/labels/train.cache... 1514 images, 1200 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1514/1514 453.6Mit/s 0.0s\n",
            "WARNING ‚ö†Ô∏è Box and segment counts should be equal, but got len(segments) = 167, len(boxes) = 398. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 437.4¬±156.3 MB/s, size: 1418.6 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/combined/labels/val.cache... 255 images, 150 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 255/255 13.9Mit/s 0.0s\n",
            "WARNING ‚ö†Ô∏è Box and segment counts should be equal, but got len(segments) = 59, len(boxes) = 139. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000667, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
            "Plotting labels to /content/runs/detect/train4/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/detect/train4\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      1/100      3.32G     0.9184      5.282        1.4          2        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 95/95 1.3s/it 2:05\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 3.1s/it 25.0s\n",
            "                   all        255        139      0.647      0.619      0.643      0.397\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      2/100      3.32G      1.026       3.81       1.44          6        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 95/95 1.1it/s 1:28\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 3.1it/s 2.6s\n",
            "                   all        255        139      0.665      0.554      0.607      0.388\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      3/100      3.32G      1.167      3.634      1.556          4        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 95/95 1.0it/s 1:33\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 2.3it/s 3.4s\n",
            "                   all        255        139      0.615      0.712      0.648      0.364\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      4/100      3.32G      1.215      3.547      1.611          5        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 95/95 1.1it/s 1:28\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 2.4it/s 3.4s\n",
            "                   all        255        139      0.657      0.489      0.568      0.325\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      5/100      3.32G      1.205       2.62      1.584          8        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 95/95 1.1it/s 1:26\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 2.6it/s 3.1s\n",
            "                   all        255        139       0.68      0.657      0.708      0.439\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      6/100      3.33G      1.127      2.312      1.525          7        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 95/95 1.1it/s 1:26\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 2.5it/s 3.2s\n",
            "                   all        255        139      0.824      0.573       0.72      0.445\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      7/100      3.34G      1.183      2.001      1.551          9        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 95/95 1.0s/it 1:35\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 3.0it/s 2.6s\n",
            "                   all        255        139      0.625      0.712      0.702      0.456\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      8/100      3.34G      1.166      1.951      1.522          6        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 95/95 1.1it/s 1:29\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 2.0it/s 3.9s\n",
            "                   all        255        139      0.708      0.699      0.751      0.477\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      9/100      3.34G       1.09      1.665      1.467          7        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 95/95 1.0it/s 1:32\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 3.2it/s 2.5s\n",
            "                   all        255        139      0.726      0.723       0.78      0.564\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     10/100      3.34G      1.047      1.514      1.432          5        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 95/95 1.1it/s 1:26\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 3.0it/s 2.7s\n",
            "                   all        255        139      0.721      0.687      0.746      0.516\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     11/100      3.34G      1.112      1.703       1.52          8        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 95/95 1.1it/s 1:24\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 3.5it/s 2.3s\n",
            "                   all        255        139      0.764      0.727        0.8      0.562\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     12/100      3.34G      1.081      1.654       1.48          8        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 95/95 1.1it/s 1:26\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 3.3it/s 2.4s\n",
            "                   all        255        139      0.801      0.705      0.802      0.563\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     13/100      3.34G      1.048      1.463      1.466          5        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 95/95 1.1it/s 1:27\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 3.8it/s 2.1s\n",
            "                   all        255        139      0.677      0.738      0.768       0.54\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     14/100      3.34G     0.9689      1.372      1.407          6        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 95/95 1.1it/s 1:25\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 3.2it/s 2.5s\n",
            "                   all        255        139      0.762      0.759      0.825      0.598\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     15/100      3.34G     0.9885      1.341       1.42          7        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 95/95 1.1it/s 1:26\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 3.9it/s 2.1s\n",
            "                   all        255        139      0.869      0.812      0.898      0.653\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     16/100      3.34G     0.9841      1.325      1.417          8        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 95/95 1.1it/s 1:26\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 2.8it/s 2.8s\n",
            "                   all        255        139      0.833      0.791      0.867      0.633\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     17/100      3.34G      1.007      1.375      1.417          4        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 95/95 1.1it/s 1:24\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 2.5it/s 3.2s\n",
            "                   all        255        139       0.81      0.777      0.829      0.588\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     18/100      3.34G     0.9901      1.271      1.399          5        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 95/95 1.1it/s 1:29\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 3.2it/s 2.5s\n",
            "                   all        255        139        0.7      0.734      0.753      0.534\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     19/100      3.34G     0.9577      1.215      1.366          6        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 95/95 1.1it/s 1:27\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 3.2it/s 2.5s\n",
            "                   all        255        139      0.831      0.813       0.87       0.68\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     20/100      3.34G     0.9401      1.246      1.392          4        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 95/95 1.1it/s 1:27\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 3.7it/s 2.2s\n",
            "                   all        255        139      0.775      0.817      0.848      0.616\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     21/100      3.34G      0.971      1.273      1.364         12        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 95/95 1.1it/s 1:28\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 3.3it/s 2.5s\n",
            "                   all        255        139      0.813      0.846      0.906      0.668\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     22/100      3.34G     0.8801      1.133      1.357         15        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 95/95 1.2it/s 1:23\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 3.5it/s 2.3s\n",
            "                   all        255        139      0.914      0.763      0.868      0.638\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     23/100      3.34G     0.8627      1.123        1.3         12        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 95/95 1.1it/s 1:25\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 3.5it/s 2.3s\n",
            "                   all        255        139      0.847      0.856      0.913      0.727\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     24/100      3.34G     0.9414      1.274      1.356         11        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 95/95 1.1it/s 1:25\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 3.9it/s 2.0s\n",
            "                   all        255        139      0.886      0.791      0.891      0.688\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     25/100      3.34G     0.8868      1.091      1.349          8        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 95/95 1.1it/s 1:28\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 4.0it/s 2.0s\n",
            "                   all        255        139       0.87      0.842      0.893      0.691\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     26/100      3.34G     0.7986       1.05      1.267          0        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 95/95 1.1it/s 1:24\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 3.3it/s 2.4s\n",
            "                   all        255        139      0.908      0.786      0.901      0.683\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     27/100      3.34G      0.863      1.172      1.315          5        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 95/95 1.1it/s 1:25\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 3.9it/s 2.0s\n",
            "                   all        255        139       0.86      0.842      0.891      0.706\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     28/100      3.34G     0.8361      1.119      1.291          4        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 95/95 1.1it/s 1:27\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 3.1it/s 2.6s\n",
            "                   all        255        139      0.949      0.799      0.923      0.702\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     29/100      3.35G     0.8778      1.058      1.309          4        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 95/95 1.1it/s 1:27\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 3.3it/s 2.4s\n",
            "                   all        255        139      0.893       0.84      0.888        0.7\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     30/100      3.35G     0.8537      1.071      1.323          7        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 95/95 1.1it/s 1:25\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 3.4it/s 2.4s\n",
            "                   all        255        139      0.874        0.9       0.92      0.694\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     31/100      3.35G      0.833     0.9967      1.281          3        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 95/95 1.1it/s 1:27\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 4.1it/s 1.9s\n",
            "                   all        255        139      0.908      0.892      0.934      0.717\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     32/100      3.35G     0.8025     0.9364      1.268          4        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 95/95 1.1it/s 1:27\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 3.9it/s 2.1s\n",
            "                   all        255        139       0.86      0.841      0.903      0.708\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     33/100      3.35G     0.8064     0.9316      1.261          8        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 95/95 1.1it/s 1:26\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 3.4it/s 2.4s\n",
            "                   all        255        139      0.855      0.871      0.901      0.704\n",
            "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 10 epochs. Best results observed at epoch 23, best model saved as best.pt.\n",
            "To update EarlyStopping(patience=10) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
            "\n",
            "33 epochs completed in 0.851 hours.\n",
            "Optimizer stripped from /content/runs/detect/train4/weights/last.pt, 5.5MB\n",
            "Optimizer stripped from /content/runs/detect/train4/weights/best.pt, 5.5MB\n",
            "\n",
            "Validating /content/runs/detect/train4/weights/best.pt...\n",
            "Ultralytics 8.4.14 üöÄ Python-3.12.12 torch-2.9.0+cu128 CUDA:0 (Tesla T4, 14913MiB)\n",
            "YOLO11n summary (fused): 101 layers, 2,584,297 parameters, 0 gradients, 6.3 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 4.1s/it 32.9s\n",
            "                   all        255        139      0.917      0.798      0.909      0.744\n",
            "             trash_bin        105        139      0.917      0.798      0.909      0.744\n",
            "Speed: 0.2ms preprocess, 120.4ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/detect/train4\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
              "\n",
              "ap_class_index: array([10])\n",
              "box: ultralytics.utils.metrics.Metric object\n",
              "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x793f6a1c97c0>\n",
              "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
              "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,\n",
              "            0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.98837,     0.97753,     0.97753,     0.97753,     0.97753,     0.97753,     0.97753,     0.97753,     0.97753,     0.97753,     0.97753,\n",
              "            0.97753,     0.97753,     0.97753,     0.97753,     0.97753,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,\n",
              "            0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,\n",
              "            0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,\n",
              "            0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.95327,\n",
              "            0.95327,     0.95327,     0.95327,     0.95327,     0.95327,     0.95327,     0.95327,     0.95327,     0.95327,     0.95327,     0.95327,     0.95327,     0.95327,     0.95327,     0.95327,     0.95327,     0.95327,     0.95327,     0.95327,     0.95327,     0.95327,     0.94643,     0.94643,\n",
              "            0.94643,     0.94643,     0.94643,     0.94643,     0.94643,     0.94643,     0.94643,     0.94643,     0.94643,     0.94643,     0.94643,     0.94643,     0.94643,     0.94643,     0.94643,     0.94643,     0.94643,     0.94643,     0.94643,     0.94643,     0.94643,     0.94643,     0.94643,\n",
              "            0.94643,     0.94643,     0.94643,      0.9386,      0.9386,      0.9386,      0.9386,      0.9386,      0.9386,      0.9386,      0.9386,     0.93103,     0.93103,     0.93103,     0.93103,     0.93103,     0.93103,     0.93103,     0.92373,     0.92373,     0.92373,     0.92373,     0.92373,\n",
              "            0.92373,     0.92373,     0.91736,     0.91736,     0.91736,     0.91736,     0.91736,     0.91736,     0.91736,     0.91736,     0.91736,     0.91736,     0.91736,     0.91736,     0.91736,     0.91736,       0.896,       0.896,       0.896,       0.896,       0.896,       0.896,       0.896,\n",
              "            0.88281,     0.88281,     0.88281,     0.88281,     0.88281,     0.88281,     0.88281,     0.88281,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.84892,     0.84892,     0.84892,     0.84892,     0.84892,     0.84892,     0.84892,     0.84892,\n",
              "            0.84892,     0.84892,     0.84892,     0.84892,     0.84892,     0.84892,     0.84892,     0.84892,     0.84892,     0.84892,     0.84892,     0.84892,     0.84892,     0.84892,     0.84892,     0.84892,     0.84892,     0.84892,     0.84892,     0.84892,     0.84892,     0.82313,     0.82313,\n",
              "            0.82313,     0.82313,     0.82313,     0.82313,     0.82313,     0.82313,     0.82313,     0.82313,     0.82313,     0.82313,     0.82313,     0.82313,     0.82313,     0.82313,     0.82313,     0.82313,     0.82313,     0.82313,     0.82313,      0.7625,      0.7625,      0.7625,      0.7625,\n",
              "             0.7625,      0.7625,      0.7625,      0.7193,      0.7193,      0.7193,      0.7193,      0.7193,      0.7193,      0.7193,      0.7193,     0.67027,     0.67027,     0.67027,     0.67027,     0.67027,     0.67027,     0.67027,     0.63131,     0.63131,     0.63131,     0.63131,     0.63131,\n",
              "            0.63131,     0.63131,     0.61765,     0.61765,     0.61765,     0.61765,     0.61765,     0.61765,     0.61765,     0.57991,     0.57991,     0.57991,     0.57991,     0.57991,     0.57991,     0.57991,     0.56637,     0.56637,     0.56637,     0.56637,     0.56637,     0.56637,     0.56637,\n",
              "            0.53527,     0.53527,     0.53527,     0.53527,     0.53527,     0.53527,     0.53527,     0.53527,     0.52209,     0.52209,     0.52209,     0.52209,     0.52209,     0.52209,     0.52209,     0.51575,     0.51575,     0.51575,     0.51575,     0.51575,     0.51575,     0.51575,     0.45361,\n",
              "            0.45361,     0.45361,     0.45361,     0.45361,     0.45361,     0.45361,     0.39349,     0.39349,     0.39349,     0.39349,     0.39349,     0.39349,     0.39349,      0.3401,      0.3401,      0.3401,      0.3401,      0.3401,      0.3401,      0.3401,      0.3401,     0.18961,     0.18961,\n",
              "            0.18961,     0.18961,     0.18961,     0.18961,     0.18961,     0.18255,     0.18255,     0.18255,     0.18255,     0.18255,     0.18255,     0.18255,     0.16156,     0.16156,     0.16156,     0.16156,     0.16156,     0.16156,     0.16156,    0.069627,    0.069627,    0.069627,    0.069627,\n",
              "           0.069627,    0.069627,    0.069627,    0.034776,    0.034776,    0.034776,    0.034776,    0.034776,    0.034776,    0.034776,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[   0.045837,    0.045837,    0.077986,     0.10399,     0.12843,     0.14788,     0.16739,     0.18228,     0.19813,     0.21268,     0.22607,     0.23775,     0.25081,     0.26115,     0.27132,     0.27741,       0.286,     0.29455,     0.30114,     0.30839,     0.31664,     0.32041,     0.32758,\n",
              "            0.33677,     0.34586,      0.3506,      0.3551,     0.35817,     0.36366,     0.36762,     0.37503,     0.38131,     0.38744,     0.39358,     0.39987,     0.40366,     0.40806,     0.41182,     0.41518,     0.42002,     0.42523,      0.4306,     0.43529,     0.44128,     0.44485,     0.44881,\n",
              "            0.45279,     0.45328,     0.45658,     0.45779,     0.46247,     0.46659,     0.46813,      0.4739,     0.47816,     0.48358,       0.486,     0.49023,     0.49322,     0.49829,     0.50175,     0.50322,     0.50513,     0.50649,     0.50995,     0.51113,     0.51295,      0.5175,     0.51968,\n",
              "            0.52028,     0.52191,      0.5231,     0.52463,     0.52711,     0.52969,     0.53137,     0.53241,      0.5368,     0.53757,     0.53835,     0.54286,     0.54488,      0.5454,     0.54579,     0.54617,     0.54688,     0.54878,     0.55268,     0.55608,     0.55638,     0.55756,     0.56056,\n",
              "            0.56419,     0.56683,     0.56934,     0.57027,     0.57173,     0.57769,     0.57798,     0.57826,     0.57854,     0.57882,     0.58293,     0.58382,     0.58598,     0.58886,      0.5924,     0.59613,     0.59789,     0.59924,     0.60094,     0.60162,     0.60201,     0.60241,     0.60302,\n",
              "            0.60476,     0.60599,     0.60684,     0.61008,     0.61076,     0.61295,     0.61091,      0.6116,     0.61282,     0.61421,     0.61503,     0.61706,     0.61927,     0.62019,     0.62119,     0.62333,     0.62562,     0.62644,     0.62891,     0.63027,     0.63093,     0.63151,       0.632,\n",
              "            0.63248,     0.63473,     0.63631,      0.6377,     0.63855,      0.6413,     0.64246,     0.64311,     0.64376,     0.64485,     0.64877,     0.65078,     0.65182,     0.65246,     0.65309,     0.65353,     0.65382,     0.65411,     0.65441,      0.6547,     0.65499,     0.65527,     0.65556,\n",
              "            0.65585,     0.65613,     0.65642,     0.65725,     0.65922,     0.66083,     0.66244,     0.66452,     0.66625,     0.66504,     0.66382,      0.6641,     0.66565,     0.66764,      0.6694,      0.6684,     0.66874,     0.66908,     0.66942,     0.66976,      0.6701,     0.67192,     0.67206,\n",
              "             0.6722,     0.67234,     0.67248,     0.67262,     0.67276,      0.6729,     0.67305,     0.67319,     0.67333,     0.67347,     0.67361,     0.67487,     0.67721,     0.67867,     0.67748,     0.67928,     0.67977,     0.68026,     0.68076,     0.68143,     0.68213,     0.68341,      0.6861,\n",
              "            0.68698,      0.6877,      0.6887,     0.69222,       0.694,      0.6946,     0.69519,     0.69624,     0.69773,     0.69809,     0.69845,     0.69882,     0.69918,     0.69968,     0.70061,     0.69789,     0.69836,     0.69884,     0.69932,     0.69994,     0.70138,     0.70198,     0.70238,\n",
              "            0.70278,     0.70318,     0.70357,     0.70398,     0.70438,     0.70478,     0.70518,      0.7056,      0.7065,      0.7074,     0.70915,     0.70646,     0.70612,     0.70642,     0.70672,     0.70702,     0.70732,     0.70763,     0.71052,     0.71262,     0.71389,     0.71528,     0.71742,\n",
              "            0.72218,     0.72359,      0.7259,     0.72665,     0.72713,      0.7276,     0.72808,     0.72904,     0.73047,     0.73172,      0.7335,      0.7332,     0.73109,     0.73182,     0.73255,     0.73332,      0.7342,     0.73508,     0.73747,     0.73773,     0.73798,     0.73824,     0.73849,\n",
              "            0.73875,     0.73901,     0.73926,     0.73952,     0.73987,     0.74032,     0.74077,     0.74122,     0.74167,     0.73868,      0.7407,     0.74116,     0.74161,     0.74206,     0.74253,     0.74405,     0.74738,     0.74809,      0.7488,     0.74936,     0.74966,     0.74996,     0.75026,\n",
              "            0.75056,     0.75086,     0.75116,     0.75146,     0.75228,     0.75321,     0.75497,     0.75629,      0.7566,     0.75691,     0.75721,     0.75752,     0.75782,     0.75813,     0.75867,     0.76092,     0.76146,     0.76199,     0.76252,     0.76306,     0.76454,     0.76242,     0.76525,\n",
              "            0.76712,     0.76852,     0.77131,     0.77273,     0.77387,     0.77459,      0.7753,     0.77601,     0.77693,     0.77784,      0.7795,     0.78115,     0.78151,     0.78186,     0.78221,     0.78256,     0.78291,     0.78326,      0.7836,     0.78392,     0.78424,     0.78456,     0.78488,\n",
              "             0.7852,     0.78552,     0.78584,     0.78936,     0.79066,     0.79155,      0.7923,     0.79305,     0.79225,     0.78973,     0.78997,     0.79021,     0.79045,     0.79068,     0.79092,     0.79116,      0.7914,     0.79164,     0.79188,     0.79212,      0.7923,     0.79244,     0.79258,\n",
              "            0.79272,     0.79286,       0.793,     0.79314,     0.79328,     0.79343,     0.79357,     0.79371,     0.79385,     0.79399,     0.79413,     0.79427,     0.79441,     0.79455,     0.79469,     0.79494,      0.7954,     0.79587,     0.79633,     0.79679,     0.79725,     0.80023,     0.80055,\n",
              "            0.80086,     0.80118,      0.8015,     0.80182,     0.80213,     0.80245,      0.8081,     0.80845,     0.80881,     0.80916,     0.80952,     0.80987,     0.81023,     0.81058,     0.81082,     0.81105,     0.81127,     0.81149,     0.81171,     0.81193,     0.81215,     0.81238,      0.8126,\n",
              "            0.81282,     0.81304,     0.81326,     0.81342,     0.81355,     0.81368,     0.81381,     0.81394,     0.81407,      0.8142,     0.81433,     0.81446,     0.81459,     0.81472,     0.81485,     0.81498,     0.81511,     0.81524,     0.81537,      0.8155,     0.81563,     0.81576,     0.81588,\n",
              "            0.81601,     0.81535,     0.81433,     0.81331,     0.81229,     0.81236,     0.81271,     0.81306,     0.81341,     0.81376,     0.81411,     0.81446,     0.81481,     0.81551,     0.81622,     0.81692,      0.8177,     0.81933,     0.82088,     0.82231,     0.82354,      0.8245,     0.82546,\n",
              "            0.82642,     0.82739,     0.82835,      0.8296,     0.83106,     0.83166,     0.83174,     0.83181,     0.83189,     0.83196,     0.83204,     0.83212,     0.83219,     0.83227,     0.83234,     0.83242,     0.83249,     0.83257,     0.83264,     0.83272,     0.83279,     0.83287,     0.83295,\n",
              "            0.83302,      0.8331,     0.83317,     0.83325,     0.83332,      0.8334,     0.83347,     0.83355,     0.83362,      0.8337,     0.83377,     0.83385,     0.83392,       0.834,     0.83407,     0.83415,     0.83423,      0.8343,     0.83438,     0.83445,     0.83533,     0.83681,     0.84121,\n",
              "            0.84271,     0.84524,     0.84587,     0.84545,     0.84504,     0.84462,     0.84421,     0.84379,     0.84338,     0.84296,     0.84255,     0.84213,     0.84145,     0.84076,     0.84006,     0.83936,     0.83867,     0.83799,     0.83752,     0.83705,     0.83659,     0.83612,     0.83565,\n",
              "            0.83518,     0.83472,     0.83425,     0.83398,     0.83416,     0.83433,     0.83451,     0.83469,     0.83487,     0.83505,     0.83523,     0.83541,     0.83558,     0.83576,     0.83594,     0.83612,      0.8363,     0.83647,     0.83665,     0.83683,     0.83798,     0.83951,     0.84308,\n",
              "            0.84338,     0.84368,     0.84397,     0.84427,     0.84456,     0.84486,     0.84515,     0.84544,     0.84574,     0.84752,     0.84876,     0.84848,      0.8482,     0.84791,     0.84763,     0.84735,     0.84706,     0.84678,      0.8465,     0.84621,     0.84593,     0.84564,     0.84536,\n",
              "            0.84507,     0.84479,     0.84346,     0.84203,     0.84059,     0.83844,      0.8363,     0.83456,     0.83282,     0.83399,     0.83524,     0.83535,     0.83546,     0.83557,     0.83569,      0.8358,     0.83591,     0.83602,     0.83614,     0.83625,     0.83636,     0.83647,     0.83659,\n",
              "             0.8367,     0.83681,     0.83692,     0.83704,     0.83715,     0.83726,     0.83737,     0.83749,      0.8376,     0.83771,     0.83782,     0.83793,     0.83805,     0.83816,     0.83848,     0.83927,     0.84007,     0.84086,     0.84082,     0.83957,     0.83831,     0.83705,     0.84045,\n",
              "            0.84076,     0.84107,     0.84137,     0.84168,     0.84199,     0.84229,      0.8426,      0.8429,     0.84321,     0.84372,     0.84431,      0.8449,     0.84549,     0.84608,      0.8456,     0.84337,     0.84236,     0.84295,     0.84355,     0.84414,     0.84473,      0.8453,     0.84556,\n",
              "            0.84583,     0.84609,     0.84635,     0.84662,     0.84688,     0.84714,      0.8474,     0.84767,     0.84793,     0.84819,     0.84845,     0.84654,     0.84429,     0.84435,     0.84462,     0.84488,     0.84514,     0.84541,     0.84567,     0.84594,      0.8462,     0.84647,     0.84673,\n",
              "            0.84699,     0.84726,     0.84761,     0.84801,      0.8484,     0.84879,     0.84918,     0.84957,     0.84996,     0.85035,     0.85106,     0.85218,     0.85329,     0.85328,     0.85214,     0.85101,     0.84987,     0.84851,     0.84698,     0.84546,     0.84587,     0.84722,     0.84818,\n",
              "            0.84789,     0.84761,     0.84732,     0.84703,     0.84674,     0.84646,     0.84617,     0.84588,     0.84559,      0.8453,     0.84501,     0.84472,     0.84444,     0.84415,     0.84386,     0.84701,     0.84664,     0.84626,     0.84589,     0.84552,     0.84515,     0.84478,     0.84441,\n",
              "            0.84403,     0.84366,     0.84329,     0.84291,     0.84254,     0.84279,     0.84307,     0.84336,     0.84365,     0.84393,     0.84421,      0.8445,     0.84478,     0.84507,     0.84535,     0.84563,     0.84557,      0.8444,     0.84323,     0.84205,     0.84166,      0.8428,     0.84395,\n",
              "            0.83805,     0.83517,     0.83477,     0.83437,     0.83397,     0.83357,     0.83317,     0.83277,     0.83236,     0.83196,     0.83156,     0.83116,     0.83076,     0.82947,     0.82786,     0.82624,     0.82701,     0.82839,     0.82877,     0.82737,     0.82597,     0.82457,     0.82216,\n",
              "            0.81969,     0.81915,     0.81863,     0.81811,     0.81758,     0.81706,     0.81653,     0.81601,     0.81548,     0.81496,     0.81839,     0.81866,     0.81894,     0.81922,      0.8195,     0.81978,     0.82006,     0.82034,     0.82061,     0.82089,     0.82117,     0.82145,      0.8213,\n",
              "            0.82077,     0.82024,     0.81971,     0.81918,     0.81865,     0.81812,     0.81759,     0.81706,      0.8165,     0.81587,     0.81523,      0.8146,     0.81397,     0.81333,      0.8127,     0.81206,      0.8115,     0.81104,     0.81058,     0.81011,     0.80965,     0.80918,     0.80872,\n",
              "            0.80825,     0.80778,     0.80732,     0.80685,     0.80523,     0.80316,     0.80151,      0.8009,     0.80029,     0.79968,     0.79907,     0.79845,     0.79784,     0.79723,     0.79661,     0.78999,     0.78848,     0.78696,     0.78509,     0.78295,     0.78073,     0.77805,     0.77557,\n",
              "            0.77402,     0.77247,     0.77091,     0.76887,     0.76667,     0.76429,     0.76153,     0.76049,      0.7622,     0.76247,     0.76087,     0.75928,     0.75765,     0.75484,     0.75233,     0.75405,     0.75541,     0.75415,     0.75288,     0.75161,     0.75035,     0.74931,     0.74835,\n",
              "            0.74739,     0.74644,     0.74548,     0.74452,     0.74271,     0.74078,     0.73884,     0.73897,     0.73922,     0.73946,     0.73971,     0.73996,      0.7402,     0.74045,     0.74069,     0.74093,     0.74118,     0.74142,     0.74167,     0.74191,      0.7418,     0.74083,     0.73985,\n",
              "            0.73887,      0.7379,     0.73692,     0.73618,     0.73576,     0.73534,     0.73492,      0.7345,     0.73407,     0.73365,     0.73323,     0.73281,     0.73238,     0.73196,     0.73154,     0.73111,     0.73069,     0.72361,     0.71959,     0.71689,     0.71446,     0.70458,     0.69965,\n",
              "            0.69653,     0.69387,     0.69177,     0.68966,     0.68771,     0.68589,     0.68407,     0.68229,     0.68087,     0.67944,     0.67801,     0.67658,     0.66828,     0.65523,     0.64853,     0.64176,     0.63259,     0.62907,     0.62733,     0.62559,     0.62385,     0.61038,     0.60536,\n",
              "            0.60118,     0.59756,     0.58609,     0.58092,     0.57256,     0.56221,     0.55454,     0.55113,     0.54972,     0.54831,     0.54689,     0.54547,     0.53518,     0.52989,     0.51538,       0.496,     0.49266,      0.4893,     0.48109,     0.46833,     0.45549,     0.45255,      0.4496,\n",
              "            0.44636,      0.4404,      0.4344,     0.40985,     0.39864,     0.38232,     0.37586,     0.36688,     0.35699,     0.34697,     0.32295,     0.31601,     0.30592,     0.30169,     0.29814,     0.29457,     0.28396,     0.26198,     0.23437,      0.2228,     0.21452,     0.20862,      0.2043,\n",
              "             0.2009,     0.19748,     0.19217,     0.16955,     0.16335,      0.1565,     0.14811,     0.12984,     0.11924,      0.1127,    0.090339,    0.070799,    0.042957,    0.039186,    0.036031,    0.032866,     0.02969,    0.026691,    0.023815,    0.020931,    0.018038,    0.015137,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[   0.023456,    0.023456,    0.040587,    0.054869,    0.068654,     0.07994,     0.09146,     0.10043,     0.11014,      0.1192,     0.12768,     0.13518,     0.14369,     0.15052,     0.15731,     0.16162,     0.16748,     0.17337,     0.17795,      0.1833,     0.18915,     0.19214,     0.19731,\n",
              "            0.20402,     0.21073,     0.21426,     0.21764,     0.21994,      0.2241,     0.22711,     0.23279,     0.23766,     0.24243,     0.24726,     0.25225,     0.25528,     0.25881,     0.26184,     0.26456,      0.2685,     0.27278,     0.27721,     0.28111,     0.28613,     0.28913,     0.29249,\n",
              "            0.29588,      0.2963,     0.29912,     0.30017,      0.3042,     0.30777,     0.30912,     0.31417,     0.31792,     0.32274,      0.3249,     0.32869,     0.33138,     0.33598,     0.33912,     0.34138,     0.34314,     0.34439,      0.3476,      0.3487,      0.3504,     0.35465,     0.35671,\n",
              "            0.35727,     0.35882,     0.35994,     0.36139,     0.36375,     0.36621,     0.36782,     0.36881,     0.37304,     0.37379,     0.37454,     0.37892,     0.38089,      0.3814,     0.38178,     0.38215,     0.38285,     0.38471,     0.38856,     0.39192,     0.39273,     0.39462,     0.39764,\n",
              "            0.40131,     0.40398,     0.40653,     0.40749,     0.40897,     0.41511,      0.4154,     0.41569,     0.41598,     0.41627,     0.42054,     0.42146,     0.42372,     0.42673,     0.43046,     0.43441,     0.43629,     0.43773,     0.43954,     0.44027,     0.44069,     0.44112,     0.44177,\n",
              "            0.44365,     0.44497,     0.44588,      0.4494,     0.45014,     0.45251,     0.45193,     0.45268,     0.45402,     0.45555,     0.45645,      0.4587,     0.46113,     0.46216,     0.46327,     0.46566,     0.46822,     0.46913,     0.47191,     0.47345,     0.47419,     0.47485,      0.4754,\n",
              "            0.47594,      0.4785,      0.4803,     0.48188,     0.48285,       0.486,     0.48734,     0.48808,     0.48884,     0.49009,     0.49463,     0.49697,     0.49819,     0.49893,     0.49968,     0.50019,     0.50053,     0.50088,     0.50122,     0.50156,      0.5019,     0.50224,     0.50257,\n",
              "            0.50291,     0.50325,     0.50358,     0.50456,     0.50689,      0.5088,     0.51071,     0.51318,     0.51551,     0.51483,     0.51415,     0.51484,      0.5167,      0.5191,      0.5217,     0.52228,     0.52269,     0.52311,     0.52352,     0.52394,     0.52435,     0.52658,     0.52676,\n",
              "            0.52693,      0.5271,     0.52728,     0.52745,     0.52762,      0.5278,     0.52797,     0.52814,     0.52832,     0.52849,     0.52866,     0.53022,     0.53311,     0.53492,     0.53585,     0.53811,     0.53873,     0.53935,     0.53997,     0.54081,      0.5417,     0.54332,     0.54671,\n",
              "            0.54784,     0.54876,     0.55003,     0.55453,     0.55682,     0.55759,     0.55836,      0.5597,     0.56164,     0.56211,     0.56258,     0.56305,     0.56352,     0.56418,     0.56538,     0.56455,     0.56518,     0.56581,     0.56643,     0.56725,     0.56915,     0.56993,     0.57046,\n",
              "            0.57098,     0.57151,     0.57204,     0.57257,      0.5731,     0.57363,     0.57416,     0.57473,     0.57592,     0.57711,     0.57973,     0.57829,      0.5783,      0.5787,     0.57911,     0.57951,     0.57992,     0.58032,     0.58423,     0.58707,      0.5888,     0.59069,     0.59362,\n",
              "            0.60016,     0.60212,     0.60531,     0.60636,     0.60703,     0.60769,     0.60836,     0.60969,      0.6117,     0.61345,     0.61597,     0.61689,      0.6159,     0.61694,     0.61798,     0.61907,     0.62033,     0.62159,     0.62501,     0.62538,     0.62575,     0.62612,     0.62648,\n",
              "            0.62685,     0.62722,     0.62759,     0.62795,     0.62846,     0.62911,     0.62976,     0.63041,     0.63106,     0.62974,     0.63324,     0.63391,     0.63457,     0.63524,     0.63591,     0.63815,     0.64306,     0.64412,     0.64517,       0.646,     0.64645,     0.64689,     0.64734,\n",
              "            0.64779,     0.64824,     0.64868,     0.64913,     0.65035,     0.65175,     0.65439,     0.65638,     0.65684,      0.6573,     0.65777,     0.65823,     0.65869,     0.65915,     0.65996,     0.66339,      0.6642,     0.66501,     0.66582,     0.66663,     0.66985,     0.66973,      0.6741,\n",
              "            0.67701,      0.6792,     0.68357,     0.68581,      0.6876,     0.68873,     0.68986,     0.69099,     0.69244,      0.6939,     0.69654,     0.69918,     0.69975,     0.70031,     0.70088,     0.70144,     0.70201,     0.70257,     0.70311,     0.70363,     0.70415,     0.70467,     0.70518,\n",
              "             0.7057,     0.70622,     0.70674,     0.71245,     0.71457,     0.71602,     0.71725,     0.71847,     0.71875,     0.71779,     0.71818,     0.71858,     0.71897,     0.71937,     0.71976,     0.72016,     0.72056,     0.72095,     0.72135,     0.72174,     0.72204,     0.72227,     0.72251,\n",
              "            0.72274,     0.72298,     0.72321,     0.72345,     0.72368,     0.72392,     0.72415,     0.72439,     0.72462,     0.72486,     0.72509,     0.72533,     0.72556,      0.7258,     0.72603,     0.72644,     0.72722,     0.72799,     0.72877,     0.72954,     0.73032,     0.73532,     0.73586,\n",
              "             0.7364,     0.73694,     0.73747,     0.73801,     0.73855,     0.73908,     0.74873,     0.74934,     0.74995,     0.75056,     0.75117,     0.75178,     0.75239,       0.753,     0.75342,      0.7538,     0.75418,     0.75457,     0.75495,     0.75534,     0.75572,      0.7561,     0.75649,\n",
              "            0.75687,     0.75725,     0.75764,     0.75791,     0.75814,     0.75837,     0.75859,     0.75882,     0.75904,     0.75927,      0.7595,     0.75972,     0.75995,     0.76017,      0.7604,     0.76062,     0.76085,     0.76108,      0.7613,     0.76153,     0.76175,     0.76198,     0.76221,\n",
              "            0.76243,     0.76223,     0.76185,     0.76147,     0.76109,     0.76149,     0.76211,     0.76273,     0.76335,     0.76396,     0.76458,      0.7652,     0.76581,     0.76706,     0.76831,     0.76956,     0.77094,     0.77384,     0.77661,     0.77917,     0.78138,     0.78311,     0.78485,\n",
              "            0.78659,     0.78834,      0.7901,     0.79238,     0.79504,     0.79614,     0.79628,     0.79642,     0.79655,     0.79669,     0.79683,     0.79697,     0.79711,     0.79725,     0.79739,     0.79752,     0.79766,      0.7978,     0.79794,     0.79808,     0.79822,     0.79836,     0.79849,\n",
              "            0.79863,     0.79877,     0.79891,     0.79905,     0.79919,     0.79933,     0.79946,      0.7996,     0.79974,     0.79988,     0.80002,     0.80016,      0.8003,     0.80043,     0.80057,     0.80071,     0.80085,     0.80099,     0.80113,     0.80127,     0.80289,     0.80563,     0.81383,\n",
              "            0.81664,     0.82139,     0.82304,     0.82292,     0.82279,     0.82267,     0.82255,     0.82242,      0.8223,     0.82217,     0.82205,     0.82193,     0.82172,     0.82151,      0.8213,     0.82109,     0.82088,     0.82068,     0.82054,     0.82039,     0.82025,     0.82011,     0.81997,\n",
              "            0.81983,     0.81968,     0.81954,     0.81955,      0.8199,     0.82024,     0.82059,     0.82093,     0.82128,     0.82162,     0.82197,     0.82231,     0.82266,     0.82301,     0.82335,      0.8237,     0.82404,     0.82439,     0.82473,     0.82508,     0.82732,      0.8303,     0.83733,\n",
              "            0.83791,      0.8385,     0.83908,     0.83966,     0.84025,     0.84083,     0.84141,       0.842,     0.84258,     0.84613,     0.84888,      0.8488,     0.84873,     0.84866,     0.84858,     0.84851,     0.84843,     0.84836,     0.84828,     0.84821,     0.84813,     0.84806,     0.84798,\n",
              "            0.84791,     0.84783,     0.84748,      0.8471,     0.84672,     0.84614,     0.84557,      0.8451,     0.84463,     0.84832,     0.85089,     0.85113,     0.85136,     0.85159,     0.85183,     0.85206,      0.8523,     0.85253,     0.85277,       0.853,     0.85323,     0.85347,      0.8537,\n",
              "            0.85394,     0.85417,      0.8544,     0.85464,     0.85487,     0.85511,     0.85534,     0.85558,     0.85581,     0.85604,     0.85628,     0.85651,     0.85675,     0.85698,     0.85765,     0.85932,     0.86098,     0.86265,     0.86351,     0.86321,      0.8629,      0.8626,     0.86988,\n",
              "            0.87054,      0.8712,     0.87186,     0.87251,     0.87317,     0.87383,     0.87449,     0.87514,      0.8758,     0.87692,      0.8782,     0.87947,     0.88075,     0.88202,     0.88263,     0.88216,     0.88245,     0.88376,     0.88506,     0.88636,     0.88767,     0.88893,     0.88951,\n",
              "            0.89009,     0.89068,     0.89126,     0.89184,     0.89243,     0.89301,     0.89359,     0.89417,     0.89476,     0.89534,     0.89592,     0.89563,      0.8952,     0.89571,     0.89631,      0.8969,      0.8975,      0.8981,     0.89869,     0.89929,     0.89989,     0.90048,     0.90108,\n",
              "            0.90168,     0.90227,     0.90308,     0.90398,     0.90487,     0.90576,     0.90665,     0.90754,     0.90844,     0.90933,     0.91094,     0.91351,     0.91608,     0.91727,     0.91709,     0.91691,     0.91674,     0.91652,     0.91628,     0.91604,     0.91812,      0.9213,     0.92372,\n",
              "            0.92368,     0.92364,     0.92359,     0.92355,     0.92351,     0.92347,     0.92343,     0.92338,     0.92334,      0.9233,     0.92326,     0.92322,     0.92318,     0.92313,     0.92309,     0.93103,     0.93098,     0.93093,     0.93088,     0.93083,     0.93078,     0.93073,     0.93068,\n",
              "            0.93063,     0.93059,     0.93054,     0.93049,     0.93044,     0.93109,     0.93179,     0.93249,     0.93318,     0.93388,     0.93458,     0.93528,     0.93597,     0.93667,     0.93737,     0.93806,     0.93856,     0.93842,     0.93828,     0.93815,     0.93901,     0.94187,     0.94474,\n",
              "            0.94574,     0.94544,     0.94539,     0.94535,     0.94531,     0.94527,     0.94522,     0.94518,     0.94514,     0.94509,     0.94505,     0.94501,     0.94497,     0.94483,     0.94465,     0.94448,     0.94734,     0.95095,     0.95322,      0.9531,     0.95297,     0.95284,     0.95261,\n",
              "            0.95238,     0.95233,     0.95228,     0.95223,     0.95218,     0.95213,     0.95208,     0.95204,     0.95199,     0.95194,     0.96173,      0.9625,     0.96327,     0.96404,     0.96482,     0.96559,     0.96636,     0.96714,     0.96791,     0.96868,     0.96945,     0.97023,     0.97057,\n",
              "            0.97054,     0.97051,     0.97048,     0.97045,     0.97041,     0.97038,     0.97035,     0.97032,     0.97029,     0.97025,     0.97021,     0.97017,     0.97013,      0.9701,     0.97006,     0.97002,     0.96999,     0.96996,     0.96993,      0.9699,     0.96987,     0.96985,     0.96982,\n",
              "            0.96979,     0.96976,     0.96973,      0.9697,      0.9696,     0.96948,     0.96938,     0.96934,      0.9693,     0.96926,     0.96922,     0.96919,     0.96915,     0.96911,     0.96907,     0.96865,     0.96856,     0.96846,     0.96834,      0.9682,     0.96806,     0.96788,     0.96772,\n",
              "            0.96762,     0.96752,     0.96741,     0.96728,     0.96713,     0.96697,     0.96678,     0.96882,     0.97438,      0.9775,     0.97742,     0.97735,     0.97727,     0.97714,     0.97742,     0.98324,     0.98837,     0.98834,     0.98831,     0.98827,     0.98824,     0.98822,     0.98819,\n",
              "            0.98817,     0.98815,     0.98812,      0.9881,     0.98805,       0.988,     0.98795,     0.98879,     0.98967,     0.99055,     0.99143,     0.99232,      0.9932,     0.99408,     0.99496,     0.99584,     0.99673,     0.99761,     0.99849,     0.99937,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,     0.99281,     0.99281,     0.99281,     0.98561,     0.98561,     0.98561,     0.98561,     0.98561,     0.98561,     0.98561,     0.98561,     0.98561,     0.98561,     0.97842,     0.97842,     0.97842,     0.97842,     0.97122,     0.97122,     0.96403,     0.96403,\n",
              "            0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,\n",
              "            0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.96403,     0.95683,     0.95683,     0.95683,     0.95683,     0.95683,     0.95683,     0.95683,     0.95683,\n",
              "            0.95683,     0.95683,     0.95683,     0.95683,     0.95683,     0.95683,     0.95683,     0.95683,     0.95683,     0.95683,     0.95683,     0.95683,     0.95683,     0.95683,     0.95683,     0.95683,     0.95683,     0.95683,     0.95683,     0.95683,      0.9538,     0.94964,     0.94964,\n",
              "            0.94964,     0.94964,     0.94964,     0.94964,     0.94964,     0.94964,     0.94964,     0.94964,     0.94964,     0.94964,     0.94964,     0.94964,     0.94964,     0.94964,     0.94964,     0.94964,     0.94964,     0.94964,     0.94964,     0.94964,     0.94964,     0.94964,     0.94964,\n",
              "            0.94964,     0.94964,     0.94964,     0.94964,     0.94964,     0.94964,     0.94245,     0.94245,     0.94245,     0.94245,     0.94245,     0.94245,     0.94245,     0.94245,     0.94245,     0.94245,     0.94245,     0.94245,     0.94245,     0.94245,     0.94245,     0.94245,     0.94245,\n",
              "            0.94245,     0.94245,     0.94245,     0.94245,     0.94245,     0.94245,     0.94245,     0.94245,     0.94245,     0.94245,     0.94245,     0.94245,     0.94245,     0.94245,     0.94245,     0.94245,     0.94245,     0.94245,     0.94245,     0.94245,     0.94245,     0.94245,     0.94245,\n",
              "            0.94245,     0.94245,     0.94245,     0.94245,     0.94245,     0.94245,     0.94245,     0.94245,     0.94156,     0.93899,     0.93643,     0.93525,     0.93525,     0.93525,     0.93379,     0.92806,     0.92806,     0.92806,     0.92806,     0.92806,     0.92806,     0.92806,     0.92806,\n",
              "            0.92806,     0.92806,     0.92806,     0.92806,     0.92806,     0.92806,     0.92806,     0.92806,     0.92806,     0.92806,     0.92806,     0.92806,     0.92806,     0.92806,     0.92086,     0.92086,     0.92086,     0.92086,     0.92086,     0.92086,     0.92086,     0.92086,     0.92086,\n",
              "            0.92086,     0.92086,     0.92086,     0.92086,     0.92086,     0.92086,     0.92086,     0.92086,     0.92086,     0.92086,     0.92086,     0.92086,     0.92086,     0.92086,     0.92086,     0.91367,     0.91367,     0.91367,     0.91367,     0.91367,     0.91367,     0.91367,     0.91367,\n",
              "            0.91367,     0.91367,     0.91367,     0.91367,     0.91367,     0.91367,     0.91367,     0.91367,     0.91367,     0.91367,     0.91298,     0.90762,     0.90647,     0.90647,     0.90647,     0.90647,     0.90647,     0.90647,     0.90647,     0.90647,     0.90647,     0.90647,     0.90647,\n",
              "            0.90647,     0.90647,     0.90647,     0.90647,     0.90647,     0.90647,     0.90647,     0.90647,     0.90647,     0.90647,     0.90647,     0.90357,     0.89928,     0.89928,     0.89928,     0.89928,     0.89928,     0.89928,     0.89928,     0.89928,     0.89928,     0.89928,     0.89928,\n",
              "            0.89928,     0.89928,     0.89928,     0.89928,     0.89928,     0.89928,     0.89928,     0.89928,     0.89928,     0.89322,     0.89209,     0.89209,     0.89209,     0.89209,     0.89209,     0.89209,     0.89209,     0.89209,     0.89209,     0.89209,     0.89209,     0.89209,     0.89209,\n",
              "            0.89209,     0.89209,     0.89209,     0.89209,     0.89209,     0.89209,     0.89209,     0.89209,     0.89209,     0.89209,     0.89209,     0.89209,     0.89209,     0.89209,     0.89209,     0.89209,     0.89209,     0.89209,     0.89209,     0.89209,     0.89041,     0.88489,     0.88489,\n",
              "            0.88489,     0.88489,     0.88489,     0.88489,     0.88489,     0.88489,     0.88489,     0.88489,     0.88489,     0.88489,     0.88489,     0.88489,     0.88489,     0.88489,     0.88489,     0.88489,     0.88489,     0.88489,     0.88489,     0.88489,     0.88489,     0.88489,     0.88489,\n",
              "            0.88489,     0.88489,     0.88489,     0.88489,     0.88489,     0.88489,     0.88489,     0.88489,     0.88249,      0.8777,      0.8777,      0.8777,      0.8777,      0.8777,      0.8777,      0.8777,      0.8777,      0.8777,      0.8777,      0.8777,      0.8777,      0.8777,      0.8777,\n",
              "             0.8777,      0.8777,      0.8777,      0.8777,      0.8777,      0.8777,      0.8777,      0.8777,      0.8777,      0.8777,      0.8777,      0.8777,      0.8777,      0.8777,      0.8777,      0.8777,      0.8777,      0.8777,      0.8777,      0.8777,      0.8777,      0.8777,      0.8777,\n",
              "             0.8777,      0.8777,      0.8777,      0.8777,      0.8777,      0.8777,      0.8777,      0.8777,      0.8777,      0.8777,      0.8777,      0.8777,      0.8777,      0.8777,      0.8777,      0.8777,      0.8777,      0.8777,      0.8777,      0.8777,      0.8777,      0.8777,      0.8777,\n",
              "             0.8777,      0.8777,      0.8777,      0.8777,      0.8777,      0.8777,      0.8777,      0.8777,      0.8777,      0.8777,      0.8777,      0.8777,      0.8777,      0.8777,      0.8777,      0.8777,      0.8777,      0.8777,      0.8777,      0.8777,      0.8777,      0.8777,      0.8777,\n",
              "             0.8777,     0.87642,     0.87458,     0.87273,     0.87089,      0.8705,      0.8705,      0.8705,      0.8705,      0.8705,      0.8705,      0.8705,      0.8705,      0.8705,      0.8705,      0.8705,      0.8705,      0.8705,      0.8705,      0.8705,      0.8705,      0.8705,      0.8705,\n",
              "             0.8705,      0.8705,      0.8705,      0.8705,      0.8705,      0.8705,      0.8705,      0.8705,      0.8705,      0.8705,      0.8705,      0.8705,      0.8705,      0.8705,      0.8705,      0.8705,      0.8705,      0.8705,      0.8705,      0.8705,      0.8705,      0.8705,      0.8705,\n",
              "             0.8705,      0.8705,      0.8705,      0.8705,      0.8705,      0.8705,      0.8705,      0.8705,      0.8705,      0.8705,      0.8705,      0.8705,      0.8705,      0.8705,      0.8705,      0.8705,      0.8705,      0.8705,      0.8705,      0.8705,      0.8705,      0.8705,      0.8705,\n",
              "             0.8705,      0.8705,     0.86999,     0.86925,     0.86852,     0.86778,     0.86704,      0.8663,     0.86557,     0.86483,     0.86409,     0.86335,     0.86215,     0.86093,      0.8597,     0.85847,     0.85724,     0.85604,     0.85523,     0.85441,     0.85359,     0.85277,     0.85195,\n",
              "            0.85113,     0.85031,     0.84949,     0.84892,     0.84892,     0.84892,     0.84892,     0.84892,     0.84892,     0.84892,     0.84892,     0.84892,     0.84892,     0.84892,     0.84892,     0.84892,     0.84892,     0.84892,     0.84892,     0.84892,     0.84892,     0.84892,     0.84892,\n",
              "            0.84892,     0.84892,     0.84892,     0.84892,     0.84892,     0.84892,     0.84892,     0.84892,     0.84892,     0.84892,     0.84865,     0.84816,     0.84767,     0.84718,     0.84668,     0.84619,      0.8457,     0.84521,     0.84472,     0.84423,     0.84373,     0.84324,     0.84275,\n",
              "            0.84226,     0.84177,     0.83947,     0.83702,     0.83456,     0.83088,     0.82722,     0.82427,     0.82132,     0.82014,     0.82014,     0.82014,     0.82014,     0.82014,     0.82014,     0.82014,     0.82014,     0.82014,     0.82014,     0.82014,     0.82014,     0.82014,     0.82014,\n",
              "            0.82014,     0.82014,     0.82014,     0.82014,     0.82014,     0.82014,     0.82014,     0.82014,     0.82014,     0.82014,     0.82014,     0.82014,     0.82014,     0.82014,     0.82014,     0.82014,     0.82014,     0.82014,     0.81929,     0.81718,     0.81508,     0.81297,     0.81295,\n",
              "            0.81295,     0.81295,     0.81295,     0.81295,     0.81295,     0.81295,     0.81295,     0.81295,     0.81295,     0.81295,     0.81295,     0.81295,     0.81295,     0.81295,     0.81154,     0.80786,     0.80576,     0.80576,     0.80576,     0.80576,     0.80576,     0.80576,     0.80576,\n",
              "            0.80576,     0.80576,     0.80576,     0.80576,     0.80576,     0.80576,     0.80576,     0.80576,     0.80576,     0.80576,     0.80576,     0.80255,     0.79886,     0.79856,     0.79856,     0.79856,     0.79856,     0.79856,     0.79856,     0.79856,     0.79856,     0.79856,     0.79856,\n",
              "            0.79856,     0.79856,     0.79856,     0.79856,     0.79856,     0.79856,     0.79856,     0.79856,     0.79856,     0.79856,     0.79856,     0.79856,     0.79856,     0.79763,     0.79579,     0.79394,      0.7921,     0.78989,     0.78743,     0.78497,     0.78417,     0.78417,     0.78406,\n",
              "             0.7836,     0.78314,     0.78268,     0.78222,     0.78176,      0.7813,     0.78084,     0.78038,     0.77992,     0.77945,     0.77899,     0.77853,     0.77807,     0.77761,     0.77715,      0.7769,     0.77631,     0.77572,     0.77513,     0.77454,     0.77395,     0.77336,     0.77277,\n",
              "            0.77218,     0.77159,       0.771,     0.77041,     0.76982,     0.76978,     0.76978,     0.76978,     0.76978,     0.76978,     0.76978,     0.76978,     0.76978,     0.76978,     0.76978,     0.76978,     0.76935,      0.7675,     0.76566,     0.76382,     0.76259,     0.76259,     0.76259,\n",
              "            0.75239,     0.74794,     0.74732,     0.74671,     0.74609,     0.74548,     0.74486,     0.74425,     0.74363,     0.74302,      0.7424,     0.74179,     0.74118,     0.73922,     0.73677,     0.73431,     0.73381,     0.73381,     0.73305,     0.73095,     0.72884,     0.72673,     0.72313,\n",
              "            0.71945,     0.71865,     0.71788,      0.7171,     0.71632,     0.71555,     0.71477,       0.714,     0.71322,     0.71244,     0.71223,     0.71223,     0.71223,     0.71223,     0.71223,     0.71223,     0.71223,     0.71223,     0.71223,     0.71223,     0.71223,     0.71223,     0.71182,\n",
              "            0.71104,     0.71027,     0.70949,     0.70871,     0.70794,     0.70716,     0.70638,     0.70561,     0.70479,     0.70387,     0.70295,     0.70203,     0.70111,     0.70018,     0.69926,     0.69834,     0.69753,     0.69686,     0.69619,     0.69552,     0.69485,     0.69418,     0.69351,\n",
              "            0.69284,     0.69217,      0.6915,     0.69083,      0.6885,     0.68555,      0.6832,     0.68234,     0.68147,      0.6806,     0.67973,     0.67887,       0.678,     0.67713,     0.67626,     0.66697,     0.66486,     0.66275,     0.66016,     0.65721,     0.65415,     0.65047,     0.64708,\n",
              "            0.64497,     0.64287,     0.64076,       0.638,     0.63505,     0.63185,     0.62816,      0.6259,      0.6259,     0.62498,     0.62288,     0.62077,     0.61863,     0.61494,     0.61151,     0.61151,     0.61132,     0.60968,     0.60804,      0.6064,     0.60476,     0.60342,     0.60219,\n",
              "            0.60096,     0.59973,     0.59851,     0.59728,     0.59497,     0.59251,     0.59006,     0.58993,     0.58993,     0.58993,     0.58993,     0.58993,     0.58993,     0.58993,     0.58993,     0.58993,     0.58993,     0.58993,     0.58993,     0.58993,     0.58957,     0.58834,     0.58711,\n",
              "            0.58589,     0.58466,     0.58343,      0.5825,     0.58198,     0.58145,     0.58092,      0.5804,     0.57987,     0.57934,     0.57882,     0.57829,     0.57776,     0.57724,     0.57671,     0.57618,     0.57566,     0.56692,       0.562,     0.55871,     0.55576,      0.5439,     0.53805,\n",
              "            0.53436,     0.53124,     0.52878,     0.52632,     0.52405,     0.52195,     0.51984,     0.51779,     0.51615,     0.51451,     0.51287,     0.51123,     0.50181,     0.48725,     0.47987,      0.4725,     0.46262,     0.45886,     0.45702,     0.45517,     0.45333,     0.43924,     0.43406,\n",
              "            0.42977,     0.42609,     0.41452,     0.40937,     0.40111,     0.39102,     0.38365,     0.38038,     0.37904,      0.3777,     0.37636,     0.37502,     0.36536,     0.36044,     0.34715,     0.32979,     0.32684,     0.32389,     0.31674,     0.30577,     0.29491,     0.29245,     0.28999,\n",
              "             0.2873,     0.28238,     0.27746,     0.25774,     0.24894,     0.23634,     0.23142,     0.22465,     0.21727,      0.2099,     0.19257,     0.18766,     0.18058,     0.17764,     0.17518,     0.17272,     0.16547,     0.15073,     0.13274,     0.12537,     0.12015,     0.11646,     0.11377,\n",
              "            0.11167,     0.10956,      0.1063,    0.092629,    0.088941,    0.084895,    0.079979,    0.069429,    0.063402,    0.059714,    0.047306,    0.036699,     0.02195,    0.019985,    0.018346,    0.016707,    0.015069,    0.013526,    0.012051,    0.010576,   0.0091012,   0.0076263,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
              "fitness: np.float64(0.7439801141542604)\n",
              "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
              "maps: array([    0.74398,     0.74398,     0.74398,     0.74398,     0.74398,     0.74398,     0.74398,     0.74398,     0.74398,     0.74398,     0.74398])\n",
              "names: {0: 'plastic', 1: 'glass', 2: 'metal', 3: 'paper', 4: 'cigarette', 5: 'food_wrapper', 6: 'styrofoam', 7: 'rubber_textile', 8: 'organic', 9: 'electronics_other', 10: 'trash_bin'}\n",
              "nt_per_class: array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139])\n",
              "nt_per_image: array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 105])\n",
              "results_dict: {'metrics/precision(B)': 0.9172663538193842, 'metrics/recall(B)': 0.7976312643578831, 'metrics/mAP50(B)': 0.9085127821958083, 'metrics/mAP50-95(B)': 0.7439801141542604, 'fitness': 0.7439801141542604}\n",
              "save_dir: PosixPath('/content/runs/detect/train4')\n",
              "speed: {'preprocess': 0.22971763528224912, 'inference': 120.44027456470882, 'loss': 0.00028805098183653957, 'postprocess': 2.63464666666051}\n",
              "stats: {'tp': [], 'conf': [], 'pred_cls': [], 'target_cls': [], 'target_img': []}\n",
              "task: 'detect'"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **STEP 6 ‚Äî Download trained model**"
      ],
      "metadata": {
        "id": "qQ5kBw2S6Uzw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/runs/detect/train4/weights/best.pt\")\n"
      ],
      "metadata": {
        "id": "scuFucvT6kht",
        "outputId": "9f1e2975-b599-4979-8669-8357fdbca187",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "Cannot find file: /content/runs/detect/train4/weights/best.pt",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1898443838.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/runs/detect/train4/weights/best.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    228\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Cannot find file: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=undefined-variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m   \u001b[0mcomm_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_IPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomm_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Cannot find file: /content/runs/detect/train4/weights/best.pt"
          ]
        }
      ]
    }
  ]
}