{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YOLO11 Tutorial",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/simbakm/training_yolov11_notebook/blob/main/examples/tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6MPjfT5NrKQ"
      },
      "source": [
        "# **starting Point @ simbakm Training YOlo  version 11 bold text**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mGmQbAO5pQb"
      },
      "source": [
        "# Setup\n",
        "\n",
        "pip install `ultralytics` and [dependencies](https://github.com/ultralytics/ultralytics/blob/main/pyproject.toml) and check software and hardware.\n",
        "\n",
        "[![PyPI - Version](https://img.shields.io/pypi/v/ultralytics?logo=pypi&logoColor=white)](https://pypi.org/project/ultralytics/) [![Downloads](https://static.pepy.tech/badge/ultralytics)](https://clickpy.clickhouse.com/dashboard/ultralytics) [![PyPI - Python Version](https://img.shields.io/pypi/pyversions/ultralytics?logo=python&logoColor=gold)](https://pypi.org/project/ultralytics/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbvMlHd_QwMG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcdd06d9-abfd-4030-a505-f34e19fb46c6"
      },
      "source": [
        "!uv pip install ultralytics\n",
        "!pip install roboflow kagglehub\n",
        "from collections import defaultdict\n",
        "from ultralytics import YOLO\n",
        "from google.colab import files\n",
        "import ultralytics\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "import os, random, shutil\n",
        "import json\n",
        "ultralytics.checks()\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.4.14 üöÄ Python-3.12.12 torch-2.10.0+cu128 CUDA:0 (Tesla T4, 14913MiB)\n",
            "Setup complete ‚úÖ (2 CPUs, 12.7 GB RAM, 46.8/112.6 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**check for GPU**"
      ],
      "metadata": {
        "id": "2BwEhVXdwnri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "print(f\"Using {device} device.\")"
      ],
      "metadata": {
        "id": "1JBHKWKxwnXQ",
        "outputId": "463ea5c2-5912-44b2-fd60-e0d06af954d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**STEP 2 ‚Äî Download the Roboflow dataset (YOLOv11-ready)bold text**"
      ],
      "metadata": {
        "id": "8I6sumtzqek_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**helper fuction to couint the number of files**"
      ],
      "metadata": {
        "id": "5oUlOF0jjOUJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from collections import defaultdict\n",
        "\n",
        "def count_file_types(dataset_path):\n",
        "    file_counts = defaultdict(int)\n",
        "\n",
        "    for root, dirs, files in os.walk(dataset_path):\n",
        "        for file in files:\n",
        "            ext = os.path.splitext(file)[1].lower()  # get file extension\n",
        "            file_counts[ext] += 1\n",
        "\n",
        "    print(\"File type counts:\\n\")\n",
        "    for ext, count in sorted(file_counts.items()):\n",
        "        print(f\"{ext if ext else 'No Extension'} : {count}\")\n",
        "\n",
        "    return dict(file_counts)\n"
      ],
      "metadata": {
        "id": "E-Ssey6njIMB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"YdrZFjwWblcZBkXrqqaR\")\n",
        "project = rf.workspace(\"stairs-ttqqp\").project(\"trash-bin-asn0s\")\n",
        "dataset = project.version(1).download(\"yolov11\")\n",
        "\n",
        "roboflow_path = dataset.location\n",
        "print(\"Roboflow dataset:\", roboflow_path)\n",
        "\n",
        "counts = count_file_types(roboflow_path)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwsMXa8YnYMe",
        "outputId": "0d725f5a-ffb6-430a-cf2d-1566a3aed43d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in trash-bin-1 to yolov11:: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 21999/21999 [00:01<00:00, 12894.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to trash-bin-1 in yolov11:: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 902/902 [00:00<00:00, 8213.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Roboflow dataset: /content/trash-bin-1\n",
            "File type counts:\n",
            "\n",
            ".jpg : 445\n",
            ".txt : 447\n",
            ".yaml : 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **STEP 3: Download the TACO dataset from KaggleHub**"
      ],
      "metadata": {
        "id": "xGzsfpkwp2mS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "path = kagglehub.dataset_download(\"kneroma/tacotrashdataset\")\n",
        "print(\"Downloaded to:\", path)\n",
        "counts = count_file_types(path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XS_K-gNBpbZ8",
        "outputId": "54f82936-ff29-412c-c655-200924643754"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'tacotrashdataset' dataset.\n",
            "Downloaded to: /kaggle/input/tacotrashdataset\n",
            "File type counts:\n",
            "\n",
            ".bin : 1\n",
            ".csv : 1\n",
            ".jpg : 1500\n",
            ".json : 1\n",
            ".txt : 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**STEP 4 ‚Äî Convert TACO (COCO JSON) ‚Üí YOLO format**"
      ],
      "metadata": {
        "id": "MAU8pdKBq3E6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# TACO dataset path (from KaggleHub)\n",
        "taco_path = path\n",
        "data_dir = os.path.join(taco_path, \"data\")\n",
        "\n",
        "# Load annotations\n",
        "annotations_path = os.path.join(data_dir, \"annotations.json\")\n",
        "annotations = json.load(open(annotations_path))\n",
        "\n",
        "# Output\n",
        "output_taco = \"/content/taco_yolo\"\n",
        "#delete privous derectories\n",
        "if os.path.exists(output_taco):\n",
        "    shutil.rmtree(output_taco)\n",
        "    print(\"Old taco_yolo directory removed.\")\n",
        "else:\n",
        "    print(\"No previous taco_yolo folder found.\")\n",
        "\n",
        "os.makedirs(f\"{output_taco}/images\", exist_ok=True)\n",
        "os.makedirs(f\"{output_taco}/labels\", exist_ok=True)\n",
        "\n",
        "# Map image id ‚Üí image info\n",
        "image_map = {img[\"id\"]: img for img in annotations[\"images\"]}\n",
        "\n",
        "# Find all images recursively\n",
        "all_images = {}\n",
        "image_files = glob(f\"{data_dir}/**/*.jpg\", recursive=True) + \\\n",
        "              glob(f\"{data_dir}/**/*.JPG\", recursive=True)\n",
        "\n",
        "for f in image_files:\n",
        "    all_images[os.path.relpath(f, data_dir)] = f\n",
        "\n",
        "\n",
        "print(\"Total images found:\", len(all_images))\n",
        "\n",
        "# Group annotations by image ID\n",
        "ann_by_image = {}\n",
        "for ann in annotations[\"annotations\"]:\n",
        "    img_id = ann[\"image_id\"]\n",
        "    ann_by_image.setdefault(img_id, []).append(ann)\n",
        "\n",
        "# Convert to YOLO\n",
        "for img_id, img_info in tqdm(image_map.items()):\n",
        "    filename = img_info[\"file_name\"]\n",
        "    batch_relative_path = filename  # contains batch_x/000000.jpg\n",
        "\n",
        "    if batch_relative_path not in all_images:\n",
        "        print(\"Missing image:\", batch_relative_path)\n",
        "        continue\n",
        "\n",
        "    src = all_images[batch_relative_path]\n",
        "\n",
        "    # create unique new filename based on img_id\n",
        "    new_name = f\"{img_id}.jpg\"\n",
        "    dst = f\"{output_taco}/images/{new_name}\"\n",
        "\n",
        "    shutil.copy(src, dst)\n",
        "\n",
        "    # image width/height\n",
        "    W = img_info[\"width\"]\n",
        "    H = img_info[\"height\"]\n",
        "\n",
        "    # label path (same name as image)\n",
        "    label_path = f\"{output_taco}/labels/{img_id}.txt\"\n",
        "    with open(label_path, \"w\") as f:\n",
        "        for ann in ann_by_image.get(img_id, []):\n",
        "            x, y, w, h = ann[\"bbox\"]\n",
        "\n",
        "            # convert to YOLO\n",
        "            xc = (x + w/2) / W\n",
        "            yc = (y + h/2) / H\n",
        "            w /= W\n",
        "            h /= H\n",
        "            # Create category id mapping\n",
        "            categories = annotations[\"categories\"]\n",
        "            cat_id_map = {cat[\"id\"]: i for i, cat in enumerate(categories)}\n",
        "            class_id = cat_id_map[ann[\"category_id\"]]\n",
        "\n",
        "            f.write(f\"{class_id} {xc} {yc} {w} {h}\\n\")\n",
        "\n",
        "print(\"DONE ‚Äî TACO converted to YOLO:\", output_taco)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujxSaGGlq8LN",
        "outputId": "5a4b3cb3-7ce0-42f2-882c-6da20aa4d2b2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Old taco_yolo directory removed.\n",
            "Total images found: 1500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1500/1500 [00:33<00:00, 44.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DONE ‚Äî TACO converted to YOLO: /content/taco_yolo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5: Split the dataset into Train,val and test using ratio 80|10|10**"
      ],
      "metadata": {
        "id": "2Vg63xcK29RE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Clean up old splits first\n",
        "if os.path.exists(\"/content/taco_split\"):\n",
        "    print(\"Removing old splits...\")\n",
        "    shutil.rmtree(\"/content/taco_split\")\n",
        "\n",
        "taco_img = \"/content/taco_yolo/images\"\n",
        "taco_lbl = \"/content/taco_yolo/labels\"\n",
        "\n",
        "# Verify source files exist\n",
        "images = sorted(glob(f\"{taco_img}/*.jpg\"))\n",
        "if len(images) == 0:\n",
        "    print(\"‚ùå No images found! Check paths.\")\n",
        "else:\n",
        "    print(f\"‚úÖ Found {len(images)} images\")\n",
        "    random.shuffle(images)\n",
        "\n",
        "    n = len(images)\n",
        "    train_split = int(n * 0.8)\n",
        "    val_split = int(n * 0.9)\n",
        "\n",
        "    train_files = images[:train_split]\n",
        "    val_files   = images[train_split:val_split]\n",
        "    test_files  = images[val_split:]\n",
        "\n",
        "    def copy_split(files, folder):\n",
        "        os.makedirs(f\"/content/taco_split/images/{folder}\", exist_ok=True)\n",
        "        os.makedirs(f\"/content/taco_split/labels/{folder}\", exist_ok=True)\n",
        "        for img in files:\n",
        "            lbl = img.replace(\"images\", \"labels\").replace(\".jpg\", \".txt\")\n",
        "            if os.path.exists(lbl):\n",
        "                shutil.copy(img, f\"/content/taco_split/images/{folder}/\")\n",
        "                shutil.copy(lbl, f\"/content/taco_split/labels/{folder}/\")\n",
        "            else:\n",
        "                print(f\"‚ö†Ô∏è  Warning: No label for {img}\")\n",
        "\n",
        "    copy_split(train_files, \"train\")\n",
        "    copy_split(val_files, \"val\")\n",
        "    copy_split(test_files, \"test\")\n",
        "\n",
        "    print(f\"\\nTACO split complete!\")\n",
        "    print(f\"  Train: {len(train_files)} images\")\n",
        "    print(f\"  Val: {len(val_files)} images\")\n",
        "    print(f\"  Test: {len(test_files)} images\")"
      ],
      "metadata": {
        "id": "6y816cQX26gg",
        "outputId": "e5305cbf-0448-4f3f-fdb0-bb8d717cd77a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Found 1500 images\n",
            "\n",
            "TACO split complete!\n",
            "  Train: 1200 images\n",
            "  Val: 150 images\n",
            "  Test: 150 images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Group TACO Classes into 5 & Shift IDs**\n",
        "# !!!! Do not run twice this cell !!!!"
      ],
      "metadata": {
        "id": "NMCUdIdQUPQ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Correct TACO class mapping based on actual class IDs\n",
        "# Source: https://github.com/pedropro/TACO/blob/master/scripts/class_mapping.txt\n",
        "\n",
        "taco_group_map_5 = {\n",
        "    # Class 0: Plastic Items (ALL plastic-related classes)\n",
        "    0:0,   # plastic_film\n",
        "    1:0,   # other_plastic\n",
        "    2:0,   # plastic_bag\n",
        "    3:0,   # plastic_bottle_cap\n",
        "    4:0,   # plastic_bottle\n",
        "    5:0,   # clear_plastic_bottle\n",
        "    6:0,   # plastic_cup_lid\n",
        "    7:0,   # plastic_cup\n",
        "    8:0,   # disposable_plastic_cup\n",
        "    9:0,   # plastic_container\n",
        "    10:0,  # plastic_jar\n",
        "    11:0,  # plastic_lid\n",
        "    12:0,  # plastic_plate\n",
        "    13:0,  # plastic_knife\n",
        "    14:0,  # plastic_fork\n",
        "    15:0,  # plastic_spoon\n",
        "    16:0,  # plastic_scoop\n",
        "    17:0,  # plastic_straw\n",
        "    18:0,  # plastic_other\n",
        "    55:0,  # styrofoam_piece\n",
        "    56:0,  # styrofoam_cup\n",
        "    57:0,  # food_container\n",
        "    58:0,  # other_plastic_wrapper\n",
        "    59:0,  # plastic_film_wrapper\n",
        "\n",
        "    # Class 1: Metal Items\n",
        "    19:1,  # drink_can\n",
        "    20:1,  # metal_bottle_cap\n",
        "    21:1,  # aluminium_foil\n",
        "    22:1,  # pop_tab\n",
        "    23:1,  # metal_lid\n",
        "    24:1,  # metal_can\n",
        "    25:1,  # metal_jar\n",
        "\n",
        "    # Class 2: Paper & Cardboard\n",
        "    26:2,  # normal_paper\n",
        "    27:2,  # paper_cup\n",
        "    28:2,  # corrugated_carton\n",
        "    29:2,  # drink_carton\n",
        "    30:2,  # pizza_box\n",
        "    31:2,  # paper_bag\n",
        "    32:2,  # cardboard_box\n",
        "    33:2,  # egg_carton\n",
        "    34:2,  # paper_tray\n",
        "    35:2,  # paper_plate\n",
        "    36:2,  # cardboard_packaging\n",
        "    37:2,  # tissue_paper\n",
        "    38:2,  # napkin\n",
        "    39:2,  # paper_wrapper\n",
        "\n",
        "    # Class 3: Glass Items\n",
        "    40:3,  # glass_bottle\n",
        "    41:3,  # glass_jar\n",
        "    42:3,  # broken_glass\n",
        "\n",
        "    # Class 4: Other & Unlabeled Litter\n",
        "    43:4,  # cigarette\n",
        "    44:4,  # unlabeled_litter\n",
        "    45:4,  # food_waste\n",
        "    46:4,  # organic\n",
        "    47:4,  # battery\n",
        "    48:4,  # electronic_waste\n",
        "    49:4,  # clothing\n",
        "    50:4,  # shoe\n",
        "    51:4,  # textile\n",
        "    52:4,  # rubber_band\n",
        "    53:4,  # tire\n",
        "    54:4,  # rubber_other\n",
        "}\n",
        "\n",
        "# Dictionary to count ANNOTATIONS per class\n",
        "annotation_counts = defaultdict(int)\n",
        "image_counts = defaultdict(int)\n",
        "total_images_processed = set()\n",
        "\n",
        "# Process each split\n",
        "for split in [\"train\", \"val\", \"test\"]:\n",
        "    lbl_files = glob(f\"/content/taco_split/labels/{split}/*.txt\")\n",
        "    for file in lbl_files:\n",
        "        new_lines = []\n",
        "        classes_in_image = set()\n",
        "\n",
        "        with open(file, \"r\") as f:\n",
        "            for line in f:\n",
        "                parts = line.strip().split()\n",
        "                if len(parts) > 0:\n",
        "                    original_id = int(parts[0])\n",
        "                    if original_id in taco_group_map_5:\n",
        "                        grouped_id = taco_group_map_5[original_id]\n",
        "                        parts[0] = str(grouped_id)\n",
        "                        new_lines.append(\" \".join(parts))\n",
        "\n",
        "                        # Count this annotation\n",
        "                        annotation_counts[grouped_id] += 1\n",
        "                        classes_in_image.add(grouped_id)\n",
        "\n",
        "        # Write the updated labels back to file\n",
        "        with open(file, \"w\") as f:\n",
        "            f.write(\"\\n\".join(new_lines))\n",
        "\n",
        "        # Count images per class\n",
        "        for class_id in classes_in_image:\n",
        "            image_counts[class_id] += 1\n",
        "\n",
        "        total_images_processed.add(file)\n",
        "\n",
        "# Print results\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TACO GROUPED INTO 5 CLASSES - CORRECTED MAPPING\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "class_names_5 = {\n",
        "    0: \"Plastic Items\",\n",
        "    1: \"Metal Items\",\n",
        "    2: \"Paper & Cardboard\",\n",
        "    3: \"Glass Items\",\n",
        "    4: \"Other & Unlabeled Litter\"\n",
        "}\n",
        "\n",
        "# Print ANNOTATION counts\n",
        "print(\"\\nüìä ANNOTATIONS PER CLASS:\")\n",
        "print(\"-\"*60)\n",
        "total_annotations = sum(annotation_counts.values())\n",
        "for class_id in sorted(annotation_counts.keys()):\n",
        "    count = annotation_counts[class_id]\n",
        "    percentage = (count / total_annotations) * 100\n",
        "    print(f\"  Class {class_id}: {class_names_5[class_id]:<25} {count:6d} annotations ({percentage:5.1f}%)\")\n",
        "\n",
        "print(\"-\"*60)\n",
        "print(f\"  TOTAL ANNOTATIONS: {total_annotations}\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Print IMAGE counts\n",
        "print(\"\\nüì∏ IMAGES PER CLASS:\")\n",
        "print(\"-\"*60)\n",
        "total_images = len(total_images_processed)\n",
        "for class_id in sorted(image_counts.keys()):\n",
        "    count = image_counts[class_id]\n",
        "    percentage = (count / total_images) * 100\n",
        "    print(f\"  Class {class_id}: {class_names_5[class_id]:<25} {count:5d} images ({percentage:.1f}%)\")\n",
        "\n",
        "print(\"-\"*60)\n",
        "print(f\"  TOTAL UNIQUE IMAGES: {total_images}\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Check 300-annotation threshold\n",
        "print(\"\\nüéØ TRAINING READINESS CHECK (target: 300+ annotations per class):\")\n",
        "print(\"-\"*60)\n",
        "all_good = True\n",
        "for class_id in range(5):\n",
        "    count = annotation_counts.get(class_id, 0)\n",
        "    if count >= 300:\n",
        "        status = \"‚úÖ READY\"\n",
        "    else:\n",
        "        status = f\"‚ùå NEEDS MORE (short by {300-count} annotations)\"\n",
        "        all_good = False\n",
        "    print(f\"  Class {class_id}: {class_names_5[class_id]:<25} {count:5d} annotations - {status}\")\n",
        "\n",
        "# Summary by material type\n",
        "\n",
        "print(\"\\nüìã MATERIAL BREAKDOWN:\")\n",
        "print(\"-\"*60)\n",
        "material_totals = {\n",
        "    \"Plastic (Class 0)\": annotation_counts.get(0, 0),  # Removed sum()\n",
        "    \"Metal (Class 1)\": annotation_counts.get(1, 0),    # Removed sum()\n",
        "    \"Paper (Class 2)\": annotation_counts.get(2, 0),    # Removed sum()\n",
        "    \"Glass (Class 3)\": annotation_counts.get(3, 0),    # Removed sum()\n",
        "    \"Other (Class 4)\": annotation_counts.get(4, 0)     # Removed sum()\n",
        "}\n",
        "\n",
        "for material, count in material_totals.items():\n",
        "    percentage = (count / total_annotations) * 100\n",
        "    print(f\"  {material:20}: {count:5d} annotations ({percentage:.1f}%)\")\n",
        "\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "YfJtJGTHUO7V",
        "outputId": "92c262ea-d5de-4154-c1fa-2d5e118de151",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "TACO GROUPED INTO 5 CLASSES - CORRECTED MAPPING\n",
            "============================================================\n",
            "\n",
            "üìä ANNOTATIONS PER CLASS:\n",
            "------------------------------------------------------------\n",
            "  Class 0: Plastic Items               2915 annotations ( 60.9%)\n",
            "  Class 1: Metal Items                  203 annotations (  4.2%)\n",
            "  Class 2: Paper & Cardboard           1288 annotations ( 26.9%)\n",
            "  Class 3: Glass Items                  103 annotations (  2.2%)\n",
            "  Class 4: Other & Unlabeled Litter     275 annotations (  5.7%)\n",
            "------------------------------------------------------------\n",
            "  TOTAL ANNOTATIONS: 4784\n",
            "============================================================\n",
            "\n",
            "üì∏ IMAGES PER CLASS:\n",
            "------------------------------------------------------------\n",
            "  Class 0: Plastic Items              1038 images (69.2%)\n",
            "  Class 1: Metal Items                 171 images (11.4%)\n",
            "  Class 2: Paper & Cardboard           716 images (47.7%)\n",
            "  Class 3: Glass Items                  86 images (5.7%)\n",
            "  Class 4: Other & Unlabeled Litter    216 images (14.4%)\n",
            "------------------------------------------------------------\n",
            "  TOTAL UNIQUE IMAGES: 1500\n",
            "============================================================\n",
            "\n",
            "üéØ TRAINING READINESS CHECK (target: 300+ annotations per class):\n",
            "------------------------------------------------------------\n",
            "  Class 0: Plastic Items              2915 annotations - ‚úÖ READY\n",
            "  Class 1: Metal Items                 203 annotations - ‚ùå NEEDS MORE (short by 97 annotations)\n",
            "  Class 2: Paper & Cardboard          1288 annotations - ‚úÖ READY\n",
            "  Class 3: Glass Items                 103 annotations - ‚ùå NEEDS MORE (short by 197 annotations)\n",
            "  Class 4: Other & Unlabeled Litter    275 annotations - ‚ùå NEEDS MORE (short by 25 annotations)\n",
            "\n",
            "üìã MATERIAL BREAKDOWN:\n",
            "------------------------------------------------------------\n",
            "  Plastic (Class 0)   :  2915 annotations (60.9%)\n",
            "  Metal (Class 1)     :   203 annotations (4.2%)\n",
            "  Paper (Class 2)     :  1288 annotations (26.9%)\n",
            "  Glass (Class 3)     :   103 annotations (2.2%)\n",
            "  Other (Class 4)     :   275 annotations (5.7%)\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**STEP 6 ‚Äî move trans bin to class 6**"
      ],
      "metadata": {
        "id": "kWvTXXoIEOOW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "rf_labels = glob(f\"{roboflow_path}/**/labels/*.txt\", recursive=True)\n",
        "\n",
        "for file in rf_labels:\n",
        "    lines = []\n",
        "    with open(file, \"r\") as f:\n",
        "        for line in f:\n",
        "            parts = line.strip().split()\n",
        "            if len(parts) > 0:\n",
        "                parts[0] = \"5\"  # Move to class 5(trash bin)\n",
        "                lines.append(\" \".join(parts))\n",
        "\n",
        "    if lines:  # Only write if there are lines\n",
        "        with open(file, \"w\") as f:\n",
        "            f.write(\"\\n\".join(lines))\n",
        "\n",
        "print(f\"Roboflow labels shifted to class 5 (trash bin). Processed {len(rf_labels)} files.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9KdLht_q48H",
        "outputId": "0eab0a58-5cd6-4e03-af42-7dc1d30968fe"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Roboflow labels shifted to class 5 (trash bin). Processed 445 files.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create a combined Dataset**"
      ],
      "metadata": {
        "id": "YsH4oUfVyhnZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove old combined folder\n",
        "shutil.rmtree(\"/content/combined\", ignore_errors=True)\n",
        "\n",
        "# Create combined structure\n",
        "for split in [\"train\", \"val\", \"test\"]:\n",
        "    os.makedirs(f\"/content/combined/images/{split}\", exist_ok=True)\n",
        "    os.makedirs(f\"/content/combined/labels/{split}\", exist_ok=True)\n",
        "\n",
        "# Copy TACO dataset (classes 0-4 for your 5-class scheme)\n",
        "print(\"Copying TACO dataset (classes 0-4)...\")\n",
        "taco_dirs = {\n",
        "    'train': '/content/taco_split/images/train',\n",
        "    'val': '/content/taco_split/images/val',\n",
        "    'test': '/content/taco_split/images/test'\n",
        "}\n",
        "\n",
        "taco_counts = {}\n",
        "for split, path in taco_dirs.items():\n",
        "    if os.path.exists(path):\n",
        "        # Copy images\n",
        "        !cp -r {path}/* /content/combined/images/{split}/ 2>/dev/null\n",
        "\n",
        "        # Copy labels\n",
        "        label_path = path.replace('images', 'labels')\n",
        "        if os.path.exists(label_path):\n",
        "            !cp -r {label_path}/* /content/combined/labels/{split}/ 2>/dev/null\n",
        "\n",
        "        # Count copied items\n",
        "        img_count = len(glob(f\"/content/combined/images/{split}/*.jpg\"))\n",
        "        taco_counts[split] = img_count\n",
        "        print(f\"  Copied {img_count} TACO images to {split} (classes 0-4)\")\n",
        "\n",
        "# Copy Roboflow dataset (class 5 - trash bin)\n",
        "print(\"\\nCopying Roboflow dataset (class 5 - trash bin)...\")\n",
        "\n",
        "if os.path.exists(roboflow_path):\n",
        "    roboflow_counts = {}\n",
        "    for split in ['train', 'valid', 'test']:\n",
        "        target_split = 'val' if split == 'valid' else split\n",
        "\n",
        "        # Count images BEFORE copying (to calculate how many we add)\n",
        "        before_count = len(glob(f\"/content/combined/images/{target_split}/*.jpg\"))\n",
        "\n",
        "        # Copy images\n",
        "        img_source = f\"{roboflow_path}/{split}/images\"\n",
        "        if os.path.exists(img_source):\n",
        "            !cp -r {img_source}/* /content/combined/images/{target_split}/ 2>/dev/null\n",
        "\n",
        "        # Copy labels\n",
        "        label_source = f\"{roboflow_path}/{split}/labels\"\n",
        "        if os.path.exists(label_source):\n",
        "            !cp -r {label_source}/* /content/combined/labels/{target_split}/ 2>/dev/null\n",
        "\n",
        "        # Count AFTER copying and calculate the difference\n",
        "        after_count = len(glob(f\"/content/combined/images/{target_split}/*.jpg\"))\n",
        "        copied_count = after_count - before_count\n",
        "        roboflow_counts[target_split] = copied_count\n",
        "        print(f\"  Copied {copied_count} Roboflow images to {target_split} (class 5)\")\n",
        "\n",
        "        # Verify it matches expected\n",
        "        expected = len(glob(f\"{img_source}/*.jpg\")) if os.path.exists(img_source) else 0\n",
        "        if copied_count != expected:\n",
        "            print(f\"    ‚ö†Ô∏è  Expected {expected} but copied {copied_count} - possible duplicates?\")\n",
        "else:\n",
        "    print(f\"  Warning: Roboflow path {roboflow_path} does not exist!\")\n",
        "    print(\"  Please update the roboflow_path variable with the correct path.\")\n",
        "\n",
        "# Final verification - CORRECTED for 6 classes (0-5)\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"FINAL COMBINED DATASET COUNTS (6 total classes: 0-5)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Define your 6 classes (5 TACO classes + 1 trash bin)\n",
        "class_names_6 = {\n",
        "    0: \"Plastic Items\",\n",
        "    1: \"Metal Items\",\n",
        "    2: \"Paper & Cardboard\",\n",
        "    3: \"Glass Items\",\n",
        "    4: \"Other & Unlabeled Litter\",\n",
        "    5: \"Trash Bin (Roboflow)\"\n",
        "}\n",
        "\n",
        "total_images = 0\n",
        "total_labels = 0\n",
        "\n",
        "for split in [\"train\", \"val\", \"test\"]:\n",
        "    images = glob(f\"/content/combined/images/{split}/*.jpg\")\n",
        "    labels = glob(f\"/content/combined/labels/{split}/*.txt\")\n",
        "    print(f\"\\n{split.upper():5} - Images: {len(images):6d}, Labels: {len(labels):6d}\")\n",
        "    total_images += len(images)\n",
        "    total_labels += len(labels)\n",
        "\n",
        "    # Check for missing labels\n",
        "    missing = 0\n",
        "    for img in images:\n",
        "        label = img.replace('/images/', '/labels/').replace('.jpg', '.txt')\n",
        "        if not os.path.exists(label):\n",
        "            missing += 1\n",
        "    if missing > 0:\n",
        "        print(f\"         ‚ö†Ô∏è  Warning: {missing} images missing labels in {split}\")\n",
        "    else:\n",
        "        print(f\"         ‚úÖ All images have corresponding labels\")\n",
        "\n",
        "    # Check class distribution in this split (only classes 0-5)\n",
        "    class_counts = {i:0 for i in range(6)}\n",
        "    for label_file in labels:\n",
        "        with open(label_file, 'r') as f:\n",
        "            for line in f:\n",
        "                if line.strip():\n",
        "                    parts = line.strip().split()\n",
        "                    if len(parts) > 0:\n",
        "                        class_id = int(parts[0])\n",
        "                        if class_id in class_counts:\n",
        "                            class_counts[class_id] += 1\n",
        "                        else:\n",
        "                            print(f\"         ‚ö†Ô∏è  Warning: Found class {class_id} outside range 0-5 in {label_file}\")\n",
        "\n",
        "    print(f\"         Class distribution in {split}:\")\n",
        "    for i in range(6):\n",
        "        if class_counts[i] > 0:\n",
        "            print(f\"           Class {i} ({class_names_6[i]}): {class_counts[i]:6d} annotations\")\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(f\"TOTAL - Images: {total_images}, Labels: {total_labels}\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Summary by dataset source\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"DATASET SOURCE SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "print(f\"TACO dataset (classes 0-4):\")\n",
        "for split, count in taco_counts.items():\n",
        "    print(f\"  {split}: {count} images\")\n",
        "print(f\"\\nRoboflow dataset (class 5):\")\n",
        "for split, count in roboflow_counts.items():\n",
        "    print(f\"  {split}: {count} images\")\n",
        "\n",
        "# Calculate and verify totals\n",
        "total_taco = sum(taco_counts.values())\n",
        "total_robo = sum(roboflow_counts.values())\n",
        "print(f\"\\nVERIFICATION:\")\n",
        "print(f\"  Total TACO images: {total_taco}\")\n",
        "print(f\"  Total Roboflow images: {total_robo}\")\n",
        "print(f\"  Combined total: {total_taco + total_robo}\")\n",
        "print(f\"  Actual total in folder: {total_images}\")\n",
        "if total_taco + total_robo == total_images:\n",
        "    print(f\"  ‚úÖ Counts match!\")\n",
        "else:\n",
        "    print(f\"  ‚ùå Counts don't match!\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "34PrwXcA2E8f",
        "outputId": "e54b5f71-9699-4bf3-818b-3fbfb47dc735",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying TACO dataset (classes 0-4)...\n",
            "  Copied 1200 TACO images to train (classes 0-4)\n",
            "  Copied 150 TACO images to val (classes 0-4)\n",
            "  Copied 150 TACO images to test (classes 0-4)\n",
            "\n",
            "Copying Roboflow dataset (class 5 - trash bin)...\n",
            "  Copied 314 Roboflow images to train (class 5)\n",
            "  Copied 105 Roboflow images to val (class 5)\n",
            "  Copied 26 Roboflow images to test (class 5)\n",
            "\n",
            "============================================================\n",
            "FINAL COMBINED DATASET COUNTS (6 total classes: 0-5)\n",
            "============================================================\n",
            "\n",
            "TRAIN - Images:   1514, Labels:   1514\n",
            "         ‚úÖ All images have corresponding labels\n",
            "         Class distribution in train:\n",
            "           Class 0 (Plastic Items):   2220 annotations\n",
            "           Class 1 (Metal Items):    156 annotations\n",
            "           Class 2 (Paper & Cardboard):   1013 annotations\n",
            "           Class 3 (Glass Items):     84 annotations\n",
            "           Class 4 (Other & Unlabeled Litter):    218 annotations\n",
            "           Class 5 (Trash Bin (Roboflow)):    398 annotations\n",
            "\n",
            "VAL   - Images:    255, Labels:    255\n",
            "         ‚úÖ All images have corresponding labels\n",
            "         Class distribution in val:\n",
            "           Class 0 (Plastic Items):    238 annotations\n",
            "           Class 1 (Metal Items):     27 annotations\n",
            "           Class 2 (Paper & Cardboard):    143 annotations\n",
            "           Class 3 (Glass Items):      7 annotations\n",
            "           Class 4 (Other & Unlabeled Litter):     26 annotations\n",
            "           Class 5 (Trash Bin (Roboflow)):    139 annotations\n",
            "\n",
            "TEST  - Images:    176, Labels:    176\n",
            "         ‚úÖ All images have corresponding labels\n",
            "         Class distribution in test:\n",
            "           Class 0 (Plastic Items):    457 annotations\n",
            "           Class 1 (Metal Items):     20 annotations\n",
            "           Class 2 (Paper & Cardboard):    132 annotations\n",
            "           Class 3 (Glass Items):     12 annotations\n",
            "           Class 4 (Other & Unlabeled Litter):     31 annotations\n",
            "           Class 5 (Trash Bin (Roboflow)):     32 annotations\n",
            "============================================================\n",
            "TOTAL - Images: 1945, Labels: 1945\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "DATASET SOURCE SUMMARY\n",
            "============================================================\n",
            "TACO dataset (classes 0-4):\n",
            "  train: 1200 images\n",
            "  val: 150 images\n",
            "  test: 150 images\n",
            "\n",
            "Roboflow dataset (class 5):\n",
            "  train: 314 images\n",
            "  val: 105 images\n",
            "  test: 26 images\n",
            "\n",
            "VERIFICATION:\n",
            "  Total TACO images: 1500\n",
            "  Total Roboflow images: 445\n",
            "  Combined total: 1945\n",
            "  Actual total in folder: 1945\n",
            "  ‚úÖ Counts match!\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "count the images in each category -> train,val and test"
      ],
      "metadata": {
        "id": "qjBm2R-ezndu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**step7: Create YOLO data.yaml**"
      ],
      "metadata": {
        "id": "HmgOeBR75SDJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define our 6 classes (TACO 5 classes + Trash Bin)\n",
        "final_names = [\n",
        "    # TACO grouped classes (5 classes) - classes 0-4\n",
        "    \"plastic_items\",           # class 0\n",
        "    \"metal_items\",             # class 1\n",
        "    \"paper_cardboard\",         # class 2\n",
        "    \"glass_items\",             # class 3\n",
        "    \"other_litter\",            # class 4\n",
        "\n",
        "    # Roboflow class (1 class) - class 5\n",
        "    \"trash_bin\"                # class 5\n",
        "]\n",
        "\n",
        "# Create combined.yaml\n",
        "with open(\"combined.yaml\", \"w\") as f:\n",
        "    f.write(\"# TACO (5 classes: 0-4) + Trash Bin (1 class: 5) dataset\\n\\n\")\n",
        "    f.write(\"train: /content/combined/images/train\\n\")\n",
        "    f.write(\"val: /content/combined/images/val\\n\")\n",
        "    f.write(\"test: /content/combined/images/test\\n\\n\")\n",
        "    f.write(f\"nc: {len(final_names)}  # 6 classes total (0-5)\\n\")\n",
        "    f.write(\"names:\\n\")\n",
        "    for name in final_names:\n",
        "        f.write(f\"  - {name}\\n\")\n",
        "\n",
        "print(\"‚úÖ combined.yaml created with 6 classes (0-5):\")\n",
        "for i, name in enumerate(final_names):\n",
        "    print(f\"   Class {i}: {name}\")\n",
        "\n",
        "# Verify the paths exist\n",
        "print(\"\\nVerifying paths:\")\n",
        "total_images = 0\n",
        "for split in [\"train\", \"val\", \"test\"]:\n",
        "    path = f\"/content/combined/images/{split}\"\n",
        "    if os.path.exists(path):\n",
        "        count = len(glob(f\"{path}/*.jpg\"))\n",
        "        total_images += count\n",
        "        print(f\"  {split}: {path} - {count:4d} images ‚úÖ\")\n",
        "    else:\n",
        "        print(f\"  {split}: {path} - NOT FOUND ‚ùå\")\n",
        "\n",
        "print(f\"\\nüìä TOTAL IMAGES IN COMBINED DATASET: {total_images}\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Quick class distribution check\n",
        "print(\"\\nüìã Expected class mapping:\")\n",
        "print(\"-\"*40)\n",
        "class_desc = {\n",
        "    0: \"Plastic Items (bottles, bags, wrappers, film, etc.)\",\n",
        "    1: \"Metal Items (cans, foil, caps, etc.)\",\n",
        "    2: \"Paper & Cardboard (boxes, cups, cartons, etc.)\",\n",
        "    3: \"Glass Items (bottles, jars, broken glass)\",\n",
        "    4: \"Other Litter (cigarettes, organic waste, electronics, textiles)\",\n",
        "    5: \"Trash Bin (from Roboflow dataset)\"\n",
        "}\n",
        "\n",
        "for i in range(6):\n",
        "    print(f\"  Class {i}: {final_names[i]}\")\n",
        "    print(f\"        {class_desc[i]}\")\n",
        "print(\"=\"*50)\n"
      ],
      "metadata": {
        "id": "03jXia1KqUSe",
        "outputId": "551491cb-6603-492d-c9e1-fa4fa7e2a14b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ combined.yaml created with 6 classes (0-5):\n",
            "   Class 0: plastic_items\n",
            "   Class 1: metal_items\n",
            "   Class 2: paper_cardboard\n",
            "   Class 3: glass_items\n",
            "   Class 4: other_litter\n",
            "   Class 5: trash_bin\n",
            "\n",
            "Verifying paths:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'function' object has no attribute 'glob'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4189309127.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"/content/combined/images/{split}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{path}/*.jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mtotal_images\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"  {split}: {path} - {count:4d} images ‚úÖ\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'glob'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **8: ‚Äî Train YOLOv11**"
      ],
      "metadata": {
        "id": "kCuUDEdq5j1B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Path to your combined YAML\n",
        "data_yaml = \"combined.yaml\"\n",
        "\n",
        "# Use YOLO11n pretrained on COCO as base\n",
        "model = YOLO(\"yolo11n.pt\")\n",
        "\n",
        "# Training parameters - saving to default path /content/runs/detect/train/\n",
        "model.train(\n",
        "    data=data_yaml,        # 6-class dataset (0-5)\n",
        "    epochs=100,            # max epochs\n",
        "    imgsz=640,             # image size\n",
        "    batch=16,              # adjust to GPU memory\n",
        "    device=device,         # device is already defined in previous cells\n",
        "    patience=10,           # early stopping if val mAP not improving for 10 epochs\n",
        "    save=True,             # saves best.pt automatically\n",
        "    pretrained=True,       # start from COCO weights\n",
        "    optimizer='auto',      # YOLO chooses best optimizer\n",
        "    lr0=0.01,              # initial learning rate\n",
        "    augment=True,          # enables basic augmentations\n",
        "\n",
        "    # Augmentation parameters\n",
        "    mosaic=1.0,            # mosaic augmentation (0-1 probability)\n",
        "    mixup=0.1,             # mixup augmentation (0-1 probability)\n",
        "    flipud=0.0,            # vertical flip - 0.0 as trash isn't usually upside down\n",
        "    fliplr=0.5,            # horizontal flip - useful for symmetry\n",
        "    hsv_h=0.015,           # hue jitter\n",
        "    hsv_s=0.7,             # saturation jitter\n",
        "    hsv_v=0.4,             # value (brightness) jitter\n",
        "    degrees=0.0,           # rotation (0 for no rotation - keeps annotations valid)\n",
        "    translate=0.1,         # translation\n",
        "    scale=0.5,             # scaling\n",
        "    shear=0.0,             # shear (keep 0 to avoid distortion)\n",
        "\n",
        "    # Training settings\n",
        "    deterministic=True,    # reproducible results\n",
        "    save_period=5,         # save weights every 5 epochs\n",
        "    plots=True,            # generate loss/metrics plots automatically\n",
        "    workers=8,             # number of dataloader workers\n",
        "    seed=42,               # for reproducibility\n",
        "    verbose=True           # print detailed output\n",
        "    # project and name are removed - will use default: runs/detect/train/\n",
        ")\n"
      ],
      "metadata": {
        "id": "tij-K73T5tNg",
        "outputId": "8b6250cb-4cc9-4a3e-ec8e-88e1c0dcb646",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo11n.pt to 'yolo11n.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5.4MB 149.6MB/s 0.0s\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, angle=1.0, augment=True, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=combined.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, end2end=None, epochs=100, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.1, mode=train, model=yolo11n.pt, momentum=0.937, mosaic=1.0, multi_scale=0.0, name=train, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, rle=1.0, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/detect/train, save_frames=False, save_json=False, save_period=5, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 755.1KB 40.3MB/s 0.0s\n",
            "Overriding model.yaml nc=80 with nc=6\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
            "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
            " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
            " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
            " 23        [16, 19, 22]  1    431842  ultralytics.nn.modules.head.Detect           [6, 16, None, [64, 128, 256]] \n",
            "YOLO11n summary: 182 layers, 2,591,010 parameters, 2,590,994 gradients, 6.4 GFLOPs\n",
            "\n",
            "Transferred 448/499 items from pretrained weights\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo26n.pt to 'yolo26n.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5.3MB 118.7MB/s 0.0s\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1149.2¬±1257.0 MB/s, size: 1066.3 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/combined/labels/train... 1514 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1514/1514 986.1it/s 1.5s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/combined/labels/train.cache\n",
            "WARNING ‚ö†Ô∏è Box and segment counts should be equal, but got len(segments) = 167, len(boxes) = 4089. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1184.3¬±1445.3 MB/s, size: 1259.4 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/combined/labels/val... 255 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 255/255 1.0Kit/s 0.2s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/combined/labels/val.cache\n",
            "WARNING ‚ö†Ô∏è Box and segment counts should be equal, but got len(segments) = 59, len(boxes) = 580. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
            "Plotting labels to /content/runs/detect/train/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/detect/train\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      1/100      2.35G      1.215       3.33      1.264         48        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 95/95 1.3s/it 2:04\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 2.7s/it 21.9s\n",
            "                   all        255        580      0.526      0.132      0.146     0.0935\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      2/100      2.76G      1.344      2.693      1.312         82        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 95/95 1.2it/s 1:20\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.7it/s 4.7s\n",
            "                   all        255        580      0.321      0.222      0.123     0.0753\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      3/100      2.76G      1.376      2.589      1.333         50        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 95/95 1.1it/s 1:29\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 2.1it/s 3.8s\n",
            "                   all        255        580      0.696       0.17      0.178       0.11\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      4/100      2.76G      1.382       2.48      1.326         34        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 95/95 1.1it/s 1:28\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 2.2it/s 3.7s\n",
            "                   all        255        580      0.325      0.193      0.148     0.0904\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      5/100      2.76G      1.353      2.348      1.322         57        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 95/95 1.1it/s 1:26\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 2.1it/s 3.8s\n",
            "                   all        255        580      0.695      0.168      0.181      0.118\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      6/100      2.76G      1.332      2.275      1.293         61        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 95/95 1.1it/s 1:28\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 2.6it/s 3.1s\n",
            "                   all        255        580      0.204       0.29      0.205      0.137\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      7/100      2.76G      1.315      2.237      1.283         74        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 95/95 1.1it/s 1:27\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 2.2it/s 3.6s\n",
            "                   all        255        580      0.728      0.214      0.205      0.135\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      8/100      2.76G      1.294      2.129       1.28         50        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 95/95 1.1it/s 1:27\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 2.5it/s 3.2s\n",
            "                   all        255        580       0.52      0.193      0.201      0.138\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      9/100      2.76G      1.265      2.074      1.255         50        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 95/95 1.1it/s 1:26\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 2.6it/s 3.1s\n",
            "                   all        255        580      0.417      0.272      0.232      0.153\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     10/100      2.76G      1.259      2.015      1.258        106        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 95/95 1.1it/s 1:27\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.7it/s 4.8s\n",
            "                   all        255        580      0.212      0.257      0.208      0.145\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     11/100      2.76G      1.249      2.011      1.248         34        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 95/95 1.1it/s 1:24\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.8it/s 4.4s\n",
            "                   all        255        580      0.178       0.28      0.213       0.14\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     12/100      2.76G      1.251      2.038      1.243         73        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 95/95 1.1it/s 1:26\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.8it/s 4.4s\n",
            "                   all        255        580      0.415      0.287      0.245      0.166\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     13/100      2.76G      1.228      1.962      1.246         46        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 95/95 1.1it/s 1:28\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 2.4it/s 3.4s\n",
            "                   all        255        580      0.199      0.345      0.246      0.174\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     14/100      2.76G      1.224      1.967      1.241         39        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 95/95 1.1it/s 1:24\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.9it/s 4.3s\n",
            "                   all        255        580      0.416      0.261      0.247      0.174\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     15/100      2.76G      1.205      1.906      1.234         59        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 95/95 1.1it/s 1:29\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 2.3it/s 3.5s\n",
            "                   all        255        580      0.685      0.252       0.23      0.162\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     16/100      2.76G      1.182      1.879      1.216         37        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 95/95 1.1it/s 1:26\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 2.4it/s 3.3s\n",
            "                   all        255        580      0.596       0.23      0.253      0.182\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     17/100      2.76G        1.2      1.874      1.218         42        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 95/95 1.1it/s 1:27\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 2.4it/s 3.3s\n",
            "                   all        255        580      0.315       0.27      0.243      0.181\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     18/100      2.76G      1.174      1.878      1.213         63        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 95/95 1.1it/s 1:29\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 2.6it/s 3.0s\n",
            "                   all        255        580      0.605      0.292      0.255      0.191\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     19/100      2.76G      1.157      1.819      1.202         78        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 95/95 1.1it/s 1:28\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 2.4it/s 3.3s\n",
            "                   all        255        580      0.604      0.266      0.241      0.172\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     20/100      2.76G      1.152      1.806      1.191         53        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 95/95 1.1it/s 1:29\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 2.5it/s 3.2s\n",
            "                   all        255        580       0.22      0.296      0.258      0.184\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     21/100      2.76G      1.182      1.791      1.205         48        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 95/95 1.1it/s 1:26\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 2.0it/s 4.1s\n",
            "                   all        255        580      0.294       0.28      0.265      0.198\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     22/100      2.76G      1.143      1.747      1.186         80        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 95/95 1.1it/s 1:24\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 2.3it/s 3.4s\n",
            "                   all        255        580      0.378      0.376      0.264      0.183\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     23/100      2.76G      1.136      1.745      1.174         49        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 95/95 1.1it/s 1:28\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.7it/s 4.6s\n",
            "                   all        255        580      0.252      0.345      0.271      0.196\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     24/100      2.76G      1.162      1.766      1.199         49        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 95/95 1.1it/s 1:29\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.9it/s 4.1s\n",
            "                   all        255        580      0.213      0.295      0.251      0.183\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     25/100      2.76G      1.115       1.73      1.187         48        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 95/95 1.1it/s 1:28\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 2.5it/s 3.2s\n",
            "                   all        255        580      0.266      0.341      0.287      0.214\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     26/100      2.76G      1.084      1.668      1.157         70        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 95/95 1.1it/s 1:28\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 2.6it/s 3.0s\n",
            "                   all        255        580      0.328      0.318      0.274      0.197\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     27/100      2.76G      1.105       1.71      1.176         24        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 95/95 1.1it/s 1:24\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 2.4it/s 3.4s\n",
            "                   all        255        580      0.226      0.355      0.274        0.2\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     28/100      2.76G      1.094      1.691      1.146         36        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 95/95 1.1it/s 1:29\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 2.2it/s 3.6s\n",
            "                   all        255        580      0.247       0.34      0.278      0.205\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     29/100      2.76G      1.103      1.685      1.173         30        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 95/95 1.1it/s 1:27\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 2.4it/s 3.3s\n",
            "                   all        255        580      0.242      0.304      0.275      0.202\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     30/100      2.76G      1.108      1.676      1.164         61        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 95/95 1.1it/s 1:26\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 2.4it/s 3.3s\n",
            "                   all        255        580      0.469      0.268      0.272      0.205\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     31/100      2.76G      1.091      1.662      1.162         49        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 95/95 1.1it/s 1:27\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 2.4it/s 3.4s\n",
            "                   all        255        580      0.334       0.32      0.285      0.214\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     32/100      2.76G      1.075      1.592       1.15         30        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 95/95 1.1it/s 1:26\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 2.4it/s 3.3s\n",
            "                   all        255        580      0.451      0.327      0.284      0.208\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     33/100      2.76G      1.074      1.603      1.144         51        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 95/95 1.1it/s 1:28\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 2.5it/s 3.2s\n",
            "                   all        255        580      0.309      0.323      0.292      0.216\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     34/100      2.76G      1.083      1.613      1.148         46        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 95/95 1.1it/s 1:24\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 2.6it/s 3.1s\n",
            "                   all        255        580      0.299      0.322      0.267        0.2\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     35/100      2.76G      1.068      1.601      1.146         44        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 95/95 1.1it/s 1:26\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 2.3it/s 3.5s\n",
            "                   all        255        580       0.29      0.342      0.304      0.224\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     36/100      2.76G      1.067      1.579      1.135         47        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 95/95 1.1it/s 1:26\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.8it/s 4.3s\n",
            "                   all        255        580      0.266      0.401      0.294      0.218\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     37/100      2.76G      1.053      1.577      1.136         31        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 95/95 1.1it/s 1:25\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.9it/s 4.1s\n",
            "                   all        255        580      0.288      0.351      0.288      0.213\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     38/100      2.76G      1.066      1.582      1.142         40        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 95/95 1.1it/s 1:26\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.8it/s 4.5s\n",
            "                   all        255        580      0.293      0.357      0.298      0.225\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     39/100      2.76G      1.035      1.523       1.14         77        640: 26% ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 25/95 1.9it/s 26.9s<36.7s"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **STEP 6 ‚Äî Download trained model**"
      ],
      "metadata": {
        "id": "qQ5kBw2S6Uzw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "files.download(\"/content/runs/detect/train4/weights/best.pt\")\n"
      ],
      "metadata": {
        "id": "scuFucvT6kht",
        "outputId": "9f1e2975-b599-4979-8669-8357fdbca187",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "Cannot find file: /content/runs/detect/train4/weights/best.pt",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1898443838.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/runs/detect/train4/weights/best.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    228\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Cannot find file: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=undefined-variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m   \u001b[0mcomm_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_IPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomm_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Cannot find file: /content/runs/detect/train4/weights/best.pt"
          ]
        }
      ]
    }
  ]
}